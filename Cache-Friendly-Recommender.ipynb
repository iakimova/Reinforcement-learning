{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "Semester_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifDLj3XnHk6c",
        "colab_type": "text"
      },
      "source": [
        "# Semester Project \n",
        "## Cache-Friendly Recommender with reinforcement learning\n",
        "#### IAKIMOVA Iuliia\n",
        "#### BARTHELEMY Jeanne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI1O48g-Hk6k",
        "colab_type": "text"
      },
      "source": [
        "This notebook will allow us to test our code, visualize the efficiency of our agent and test hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiT3oTSifNwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Libraries \n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "import copy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3LC1zUC8gui",
        "colab_type": "text"
      },
      "source": [
        "## Items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD2C0-Vd8f8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We define here a simplified environnement for our problem : Items part\n",
        "#Just the list of items, with similarities and cost\n",
        "\n",
        "class Items(): #part of the environnement directly dealing with items (database, costs, similariries)\n",
        "    def __init__(self, N_items):\n",
        "\n",
        "        #Creating the database of all of the items\n",
        "        # (ex: one item is one song)\n",
        "        self.n_items = N_items\n",
        "        self.items = []\n",
        "        self.ids = [] #we only have the ids of the items displayed here\n",
        "        self.similarities = np.zeros((self.n_items,self.n_items))\n",
        "        self.createItems()\n",
        "        self.computeSimilarities()\n",
        "\n",
        "    def createItems(self):\n",
        "        for i in range(self.n_items):\n",
        "            item = Item(i,random.randint(3,9))\n",
        "            self.items.append(item)\n",
        "            self.ids.append(i)\n",
        "\n",
        "\n",
        "    def computeSimilarities(self):\n",
        "        for i in tqdm(range(self.n_items)):\n",
        "            for j in range(self.n_items):\n",
        "                if i==j:\n",
        "                    self.similarities[i][j]=1\n",
        "                elif j>i:\n",
        "                    self.similarities[i][j] = random.random()\n",
        "                else:\n",
        "                    self.similarities[i][j] = self.similarities[j][i]\n",
        "\n",
        "    def display(self, print_items = False, print_similarities = False ):\n",
        "        print(\"---------------- Items ----------------\")\n",
        "        print(\"Number of items: \"+str(self.n_items))\n",
        "        if print_items:\n",
        "            print(\"*** Items list: ***\")\n",
        "            for item in self.items:\n",
        "                item.display()\n",
        "            print(\"***************\")\n",
        "        if print_similarities:\n",
        "            print(\"*** Similarities: ***\")\n",
        "            print(self.similarities)\n",
        "            print(\"***************\")\n",
        "\n",
        "class Item(): #a single item of the items database\n",
        "    def __init__(self, id , size=\"7\", binary = True, name = 'none'):\n",
        "\n",
        "        self.id = id\n",
        "        if name == 'none':\n",
        "            self.name = RandomName(size)\n",
        "        elif name != 'none':\n",
        "            self.name = name\n",
        "\n",
        "        if binary: #cached = 0, not cached = 1\n",
        "            # Parameter can be changed (proportion of cached content)\n",
        "            self.cost = int(np.random.choice([0,1], p = [0.05,0.95])) #Only a minority of items is cached\n",
        "        elif binary == False: #real numbers for costs\n",
        "            self.cost = 100*random.random()\n",
        "\n",
        "    def display(self):\n",
        "        print(\"Item \"+str(self.id)+\" -> name:\" +self.name+\", cost: \"+str(self.cost))\n",
        "\n",
        "\n",
        "def RandomName(size):\n",
        "    alphabet = \"AZERTYUIOPMLKJHGFDSQWXCVBNazertyuiopmlkjhgfdsqwxcvbn7894561230\"\n",
        "    name = \"\"\n",
        "    for i in range(size):\n",
        "        name = name + random.choice(alphabet)\n",
        "    return name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT724sNf97QZ",
        "colab_type": "text"
      },
      "source": [
        "## User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NviLXDoFjFlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Customer():\n",
        "    def __init__(self, items, recommendation, behaviour = 'random' , p_or_minSum = 0.7, specific_items = None): #p is the probability to trust\n",
        "        #The customer has this way a direct access to\n",
        "        self.items = items\n",
        "        self.recommendation = recommendation\n",
        "        if behaviour == 'specific':\n",
        "            self.specific_items = specific_items\n",
        "        #This would make us always choose the same beginning state.\n",
        "        #self.previous_choice_id = -1\n",
        "        #self.choice_id = -1 #it will be updated to the id of the next choice\n",
        "\n",
        "        #Let's instead choose a random first state:\n",
        "        self.previous_choice_id = random.randint(0, self.items.n_items -1)\n",
        "        self.choice_id = random.randint(0, self.items.n_items -1)\n",
        "        while   self.choice_id == self.previous_choice_id:\n",
        "            self.choice_id = random.randint(0, self.items.n_items -1)\n",
        "\n",
        "        self.trust_recommendation = False #If trust recommendations, this will be updated to True\n",
        "        self.behaviour = behaviour\n",
        "\n",
        "        if self.behaviour == 'similarWithSubset':\n",
        "            self.min_similarity_sum = p_or_minSum #in this case, the p_or_minSum variable can be any real number\n",
        "\n",
        "        else:\n",
        "            self.p = p_or_minSum\n",
        "            #Here p is a probability that has to be between 0 and 1 ... the lines below are ensuring that\n",
        "            if self.p <0 :\n",
        "                self.p =0\n",
        "            elif self.p >1 :\n",
        "                self.p = 1\n",
        "\n",
        "        #List used for debugging\n",
        "        self.choicesThisEpisode = np.zeros(self.items.n_items)\n",
        "\n",
        "    def choice(self):\n",
        "        if self.behaviour == 'similar':\n",
        "            self.choiceSimilar()\n",
        "\n",
        "        elif self.behaviour == \"similarWithSubset\":\n",
        "            self.choiceSimilarWithSubset()\n",
        "\n",
        "        else:\n",
        "            print(\"Error: no choice method indicated\")\n",
        "        self.choicesThisEpisode[self.choice_id] += 1\n",
        "\n",
        "    def endEpisode(self):\n",
        "        self.previous_choice_id = random.randint(0, self.items.n_items -1)\n",
        "        self.choice_id = random.randint(0, self.items.n_items -1)\n",
        "        while   self.choice_id == self.previous_choice_id:\n",
        "            self.choice_id = random.randint(0, self.items.n_items -1)\n",
        "        self.trust_recommendation = False\n",
        "        self.choicesThisEpisode = np.zeros(self.items.n_items)\n",
        "\n",
        "    def display(self, print_item = False):\n",
        "        print(\"----------- Customer -----------\")\n",
        "        print(\"Trust recommendation: \"+str(self.trust_recommendation))\n",
        "       # print(\" Previous choice: \"+str(self.previous_choice_id))\n",
        "        print(\" Choice: \"+str(self.choice_id))\n",
        "        if print_item:\n",
        "            self.items.items[self.choice_id].display()\n",
        "\n",
        "    def choiceSimilar(self): #this user has a minimum standard of \"quality\", being the similarities\n",
        "        self.trust_recommendation = False\n",
        "        self.previous_choice_id = self.choice_id\n",
        "        for id in self.recommendation.recommended_items :\n",
        "            if self.items.similarities[id][self.choice_id] >= self.p and not self.trust_recommendation:\n",
        "                self.trust_recommendation = True\n",
        "                self.choice_id = id\n",
        "                break\n",
        "        if not self.trust_recommendation: #Choose randomly among the 2 items with best similarity\n",
        "            similarities = self.items.similarities[self.choice_id]\n",
        "            self.choice_id = np.random.choice(similarities.argsort()[- 3 :])   #/!\\ with big lists, problems...\n",
        "            while self.choice_id == self.previous_choice_id :\n",
        "                self.choice_id = np.random.choice(similarities.argsort()[- 3 :])\n",
        "\n",
        "    def choiceSimilarWithSubset(self): #This user behaviour will be usable with the deep learning \"faster\" method\n",
        "        #Contrary to \"Similar\" user, it is scalable to huge catalogs of items\n",
        "        recommendation_similarities = [self.items.similarities[id][self.choice_id] for id in self.recommendation.recommended_items ]\n",
        "        recommendation_similarities_sum = np.sum(np.array(recommendation_similarities))\n",
        "        #print(self.min_similarity_sum, recommendation_similarities_sum)\n",
        "        #TODO : set this to mean instead later maybe?\n",
        "        if self.min_similarity_sum <= recommendation_similarities_sum :\n",
        "            #The recommendation is globally good enough:\n",
        "            self.trust_recommendation = True #We will pick an item into the recommendations\n",
        "            self.choice_id = int(np.random.choice(self.recommendation.recommended_items, 1, p =softmaxOfSims(recommendation_similarities)))\n",
        "            #We will pick this item with the similarities as the probabilities (with softmax transformation)\n",
        "\n",
        "        else:\n",
        "            self.trust_recommendation = False\n",
        "            self.previous_choice_id = self.choice_id\n",
        "\n",
        "    #To adapt to huge dataset, we will take the best option out of a subset of items\n",
        "    #Indeed, this is more realistic: a user would not see all of the descriptions of the items  in youtube before making a choice.\n",
        "    #The user would rather have a look at a smaller subset and make a choice within this smaller subset\n",
        "            random_subset = np.random.choice(self.items.ids, min(self.items.n_items, 10), replace=False) #Random item ids\n",
        "            #TODO : change the random subset size later\n",
        "            random_subset_similarities = np.array([self.items.similarities[id][self.choice_id] for id in random_subset]) #The similarities of the random items ids\n",
        "            while self.previous_choice_id == self.choice_id:  # To ensure we wont take two time the same item\n",
        "                random_item_sim = np.random.choice(random_subset_similarities.argsort()[- 3:])\n",
        "                self.choice_id =  int(random_subset[random_item_sim])\n",
        "        #We randomly took one of the 3 items with the best similarity, in the random subset of items\n",
        "\n",
        "\n",
        "#helper function :\n",
        "\n",
        "def softmaxOfSims(similarities): #to change similarities into probabilities\n",
        "    np_sims = np.array(similarities)\n",
        "    exponential_similarities = np.exp(np_sims)\n",
        "    return list(exponential_similarities/np.sum(exponential_similarities))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu_X8gnm-NSp",
        "colab_type": "text"
      },
      "source": [
        "## Recommendations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "929u18JD-aFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recommendation(): #part of the environnement directly dealing with recommended items\n",
        "    #no agent/AIfor the moment. The choice of the ids will be determined by the agent.\n",
        "    def __init__(self,items, N_recommended): #items is an Items object, N_recommended the number of recommendations\n",
        "\n",
        "        #About the recommended items\n",
        "        #(the list will be updated)\n",
        "        self.n_recommended =   N_recommended\n",
        "        self.recommended_items = [] #list of ids of recommended items\n",
        "        self.all_items = items #list of ALL items\n",
        "\n",
        "        # List used for debugging\n",
        "        self.choicesThisEpisode = np.zeros(self.all_items.n_items)\n",
        "\n",
        "    def recommend(self, ids): #assume we have a list of ids, we just update the list\n",
        "        if len(ids) != self.n_recommended:\n",
        "            print(\"ERROR : you must recommend exactly \"+str(self.n_recommended)+ \" items.\")\n",
        "        else:\n",
        "            self.recommended_items = ids\n",
        "        self.choicesThisEpisode[self.recommended_items] += 1\n",
        "\n",
        "    def endEpisode(self):\n",
        "        self.recommended_items = []\n",
        "        self.choicesThisEpisode = np.zeros(self.all_items.n_items)\n",
        "\n",
        "    def display(self, print_items = False):\n",
        "        print(\"---------------- Recommendations ----------------\")\n",
        "        print(\"Number of recommended items: \"+str(self.n_recommended))\n",
        "        if print_items:\n",
        "            print(\"*** Items list: ***\")\n",
        "            for item_id in self.recommended_items:\n",
        "                self.all_items.items[item_id].display()\n",
        "            print(\"***************\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDIJ0hhc-liK",
        "colab_type": "text"
      },
      "source": [
        "## Environment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTKpQ4AS-mOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environnement():\n",
        "    def __init__(self, N_items, N_recommended,behaviour=\"random\", rewardType = 'trust', rewardParameters = [1,1] ,  proba_p = 0.7 ,  specific_items = None, name = 'envi_01'): #proba_p for ramdom choice (customer)\n",
        "        self.items = Items(N_items)\n",
        "        self.recommendation = Recommendation(self.items, N_recommended)\n",
        "        self.customer = Customer( self.items, self.recommendation, behaviour, proba_p , specific_items)\n",
        "        self.name = name\n",
        "        self.rewardType = rewardType\n",
        "        self.rewardParameters = rewardParameters\n",
        "\n",
        "    def endEpisode(self):\n",
        "        self.customer.endEpisode()\n",
        "        self.recommendation.endEpisode()\n",
        "\n",
        "    #self.step to simulate new step of the environnement\n",
        "    def step(self, agentRecommendation): #here agentRecommendation is the items recommended by the agent\n",
        "        self.recommendation.recommend(agentRecommendation) #We have set the new recommendations\n",
        "        self.customer.choice()\n",
        "        reward = self.computeReward()\n",
        "        return reward\n",
        "\n",
        "\n",
        "\n",
        "    def computeReward(self):#This function will be refined to get more realistic rewards\n",
        "        if self.rewardType == 'Similarity':\n",
        "            reward = -self.items.items[self.customer.choice_id].cost * self.rewardParameters[0]\n",
        "            reward += self.items.similarities[self.customer.previous_choice_id][self.customer.choice_id] * self.rewardParameters[1]\n",
        "        elif self.rewardType == 'Trust':\n",
        "            reward = -(self.items.items[self.customer.choice_id].cost )* self.rewardParameters[0]\n",
        "            reward += self.customer.trust_recommendation * self.rewardParameters[1]\n",
        "        else:\n",
        "            print(\"Error : wrong reward type\")\n",
        "            return None\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def display(self, print_item = False):\n",
        "        print('---------ENVIRONNEMENT DISPLAY--------')\n",
        "        self.items.display(print_item)\n",
        "        self.recommendation.display()\n",
        "        self.customer.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zck8x3JytLt9",
        "colab_type": "text"
      },
      "source": [
        "## Q-Learning (Action Tuples)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD0UrzPJtMwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Same thing than the Qlearning class, but with more complex actions.\n",
        "#Indeed, before, one action was one item, now an action is a tuple (of all the recommended items).\n",
        "class QlearningActionTuples():\n",
        "    #items_size is the number of items, memory the \"memory\" hyperparameter to define the states.\n",
        "    def __init__(self, agent, items_size, memory, N_recommended,epsilon = 0.1 ,learning_rate = 0.7, gamma = 0.3, choiceMethod = \"eGreedy\"):\n",
        "        self.N_recommended = N_recommended\n",
        "        self.agent = agent\n",
        "        self.actions, self.actions_ids = self.initActions()\n",
        "        self.numActions = len(self.actions_ids)\n",
        "        self.dims =  [items_size for i in range(memory)]+[self.numActions] #the +1 for the actions\n",
        "        self.initQtable()\n",
        "        self.lr = learning_rate\n",
        "        self.choiceMethod = choiceMethod\n",
        "        self.epsilon = epsilon\n",
        "        self.gamma = gamma\n",
        "        self.recommendation =  [] #will be updated  (the id of the choice)\n",
        "\n",
        "\n",
        "    def initActions(self): #helper function to compute the actions possibilities\n",
        "        def computeActions(n,li):\n",
        "            if n==1 :\n",
        "                return li\n",
        "            else :\n",
        "                li = [prev+ [j] for prev in li for j in self.agent.environnement.items.ids if j not in prev ]\n",
        "                return computeActions(n-1, li)\n",
        "\n",
        "        actions = computeActions(self.N_recommended,[[i] for i in self.agent.environnement.items.ids] )\n",
        "        return (actions,[i for i in range(len(actions))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def initQtable(self): #We have to initialize the Qtable (and remove the possibility of recommending the currently watched item)\n",
        "        #self.Qtable = np.ones(self.dims)  # not flattened Qtable. Optimistic values (ones) to encourage exploration at the beginning.\n",
        "        #self.Qtable = np.ones(self.dims)\n",
        "        # Or we can also set everything to 0\n",
        "        self.Qtable = np.zeros(self.dims)\n",
        "        for lastState in range(self.dims[-2]):\n",
        "            for action_id in self.actions_ids :\n",
        "                if lastState in self.actions[action_id]:\n",
        "                    self.Qtable[..., lastState, action_id] = -np.inf\n",
        "\n",
        "\n",
        "        # For instance, Qtable[0][5][3] would allow us to get the list of values for actions, for the state [0,5,3] (if memory = 3)\n",
        "\n",
        "    def chooseAction(self, train_): #When we are in a new state, we get to choose a new action\n",
        "        if train_ : #a training session : we choose the choice method specific to training sessions\n",
        "            if self.choiceMethod == \"eGreedy\" :\n",
        "                self.chooseActionEGreedy()\n",
        "            else:\n",
        "                print(\"Error : Qlearning Choice Method not recognized\")\n",
        "        else: #not a training session\n",
        "            self.recommendation_id = self.chooseMaxAction(self.agent.state, 1)[0]\n",
        "            self.recommendation = self.actions[self.recommendation_id]\n",
        "\n",
        "\n",
        "    def chooseActionEGreedy(self):\n",
        "        self.recommendation = []\n",
        "        rand_ = random.random()\n",
        "        if rand_ <= self.epsilon:\n",
        "            self.chooseActionRandom()\n",
        "\n",
        "        else:\n",
        "            self.recommendation_id = self.chooseMaxAction(self.agent.state, 1)[0]\n",
        "            self.recommendation = self.actions[self.recommendation_id]\n",
        "\n",
        "\n",
        "    def chooseActionRandom(self):\n",
        "        recommendation_id = np.random.choice(self.actions_ids)\n",
        "        while self.agent.environnement.customer.choice_id in self.actions[recommendation_id]:\n",
        "            recommendation_id = np.random.choice(self.actions_ids)\n",
        "        self.recommendation_id = recommendation_id\n",
        "        self.recommendation = self.actions[self.recommendation_id][:]\n",
        "\n",
        "    #(We need to update this function to add randomness! (not select the n_recommended higher in the order of their id...)\n",
        "    def chooseMaxAction(self, state, num):\n",
        "       # self.Qtable[tuple(state)][state[-1]] = -np.inf  #to make sure we wont recommend the currently watched item\n",
        "        #return (np.flip(self.Qtable[tuple(state)]).argsort()[- num :])\n",
        "        return self.selectRandomlyMax(np.copy(self.Qtable[tuple(state)][:]), num, [])\n",
        "\n",
        "    def train(self, print_ = False):   #/!\\ to update\n",
        "        if print_:\n",
        "            self.display()\n",
        "\n",
        "        prev_state_reco = self.Qtable[tuple(self.agent.previousState)][self.recommendation_id]\n",
        "        current_state_max = self.Qtable[tuple(self.agent.state)][self.chooseMaxAction(self.agent.state, 1)][0]\n",
        "        self.Qtable[tuple(self.agent.previousState)][self.recommendation_id] = prev_state_reco + self.lr * (self.agent.reward + self.gamma * current_state_max - prev_state_reco)\n",
        "\n",
        "    def endEpisode(self):\n",
        "        self.recommendation = []\n",
        "\n",
        "    def display(self):\n",
        "        print(\"--------------------------> Q learning (tuple actions) method :\")\n",
        "        print(\" learning rate: \"+str(self.lr))\n",
        "        print(\" gamma: \"+str(self.gamma))\n",
        "        print(\">>>>> Qtable <<<<<\")\n",
        "        print(self.Qtable)\n",
        "\n",
        "    def selectRandomlyMax(self, li, n, results): #select randomly n maximums in an np.array list. Returns indices.\n",
        "        if n == 0:\n",
        "            return np.array(results)\n",
        "        else :\n",
        "            max_ = np.max(li)\n",
        "            ind = np.argwhere(li == max_).flatten()\n",
        "            choice = np.random.choice(ind)\n",
        "            results.append(choice)\n",
        "            li[choice] = -np.inf\n",
        "            return self.selectRandomlyMax(li, n-1, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HALOnaw6s-0J",
        "colab_type": "text"
      },
      "source": [
        "## Q-Learning (Linear)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-u4VBSdtA49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearQlearning():\n",
        "    #items_size is the number of items, memory the \"memory\" hyperparameter to define the states.\n",
        "    def __init__(self, agent, N_items, Memory, N_recommended, epsilon = 0.1 ,learning_rate = 0.7, gamma = 0.3, choiceMethod = \"eGreedy\"):\n",
        "        self.n_recommended = N_recommended\n",
        "        self.memory = Memory\n",
        "        self.n_items = N_items\n",
        "        self.n_inputs = self.memory + 2*self.n_recommended # TODO : adapt the self.n_inputs to the right value\n",
        "        self.weights = np.random.rand(self.n_inputs,1)  #The weights that will be used to estimate the state value\n",
        "        self.agent = agent\n",
        "        self.actions, self.actions_ids = self.initActions()\n",
        "        self.numActions = len(self.actions_ids)\n",
        "        self.lr = learning_rate\n",
        "        self.choiceMethod = choiceMethod\n",
        "        self.epsilon = epsilon\n",
        "        self.gamma = gamma\n",
        "        self.recommendation =  [] #will be updated  (the id of the choice)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          # For instance, Qtable[0][5][3] would allow us to get the list of values for actions, for the state [0,5,3] (if memory = 3)\n",
        "\n",
        "\n",
        "    def chooseAction(self, train_): #When we are in a new state, we get to choose a new action\n",
        "        if train_ : #a training session : we choose the choice method specific to training sessions\n",
        "            if self.choiceMethod == \"eGreedy\" :\n",
        "                self.chooseActionEGreedy()\n",
        "            else:\n",
        "                print(\"Error : Qlearning Choice Method not recognized\")\n",
        "        else: #not a training session\n",
        "            self.recommendation = self.chooseMaxAction(self.agent.state)[0]\n",
        "        self.recommendation_id = self.actions.index(self.recommendation)\n",
        "\n",
        "    def chooseActionEGreedy(self):\n",
        "        self.recommendation = []\n",
        "        rand_ = random.random()\n",
        "        if rand_ <= self.epsilon:\n",
        "            self.recommendation = self.chooseMaxAction(self.agent.state)[0]\n",
        "            self.chooseActionRandom()\n",
        "        else:\n",
        "            self.recommendation = self.chooseMaxAction(self.agent.state)[0]\n",
        "\n",
        "\n",
        "\n",
        "    def chooseActionRandom(self):\n",
        "        #We already have chosen the recommendation, according to the \"chooseMaxAction\" function.\n",
        "        # But one of the items is going to be changed, so that it can be chosen randomly.\n",
        "        random_recommendation = np.random.randint(0, self.n_items)\n",
        "        while self.agent.environnement.customer.choice_id == random_recommendation or random_recommendation in self.recommendation:\n",
        "            random_recommendation = np.random.randint(0, self.n_items)\n",
        "        index = np.random.randint(0,self.n_recommended)\n",
        "        self.recommendation[index] = random_recommendation\n",
        "\n",
        "\n",
        "    def initActions(self): #helper function to compute the actions possibilities\n",
        "        def computeActions(n,li):\n",
        "            if n==1 :\n",
        "                return li\n",
        "            else :\n",
        "                li = [prev+ [j] for prev in li for j in self.agent.environnement.items.ids if j not in prev ]\n",
        "                return computeActions(n-1, li)\n",
        "\n",
        "        actions = computeActions(self.n_recommended,[[i] for i in self.agent.environnement.items.ids] )\n",
        "        return (actions,[i for i in range(len(actions))])\n",
        "\n",
        "\n",
        "    def chooseMaxAction(self, state):\n",
        "        #This function could be improved in order to be \"parallelized\", or more efficient.\n",
        "        #However, this work is mainly for theoritical study, we are letting aside the\n",
        "        # 'efficiency' aspect of the code for the moment\n",
        "        current_item = self.agent.environnement.customer.choice_id\n",
        "        best_indice = None\n",
        "        best_value = -np.inf\n",
        "        for i in self.actions_ids:\n",
        "            action = self.actions[i][:]\n",
        "            if current_item not in action:\n",
        "                value = self.getValue(state,action)\n",
        "                if value > best_value:\n",
        "                    best_indice = i\n",
        "                    best_value = value\n",
        "        return  self.actions[best_indice][:] , best_value\n",
        "\n",
        "    # In the logistic-inspired model, this is just the matrix multiplication.\n",
        "    def getValue(self,state,action):\n",
        "        return np.dot(np.array(self.getInput(state,action)), self.weights)[0]\n",
        "\n",
        "    # Here we \"transform\" the input in order to get costs and similarities, instead of item id, as an input\n",
        "    #TODO : see why the basic item_id inputs was not working at all\n",
        "    def getInput(self, state, action):\n",
        "        input = []\n",
        "        #Adding costs of states in memory:\n",
        "        for item_id in state:\n",
        "            input.append(self.agent.environnement.items.items[item_id].cost)\n",
        "        # Adding costs of items of the action:\n",
        "        for item_id in action:\n",
        "            input.append(self.agent.environnement.items.items[item_id].cost)\n",
        "        #Adding similarities of the last state with all items in action\n",
        "        for item_id in action:\n",
        "            input.append(self.agent.environnement.items.similarities[state[-1]][item_id])\n",
        "        #print(state,action,  input)\n",
        "        return input\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, print_ = False):   #/!\\ to update\n",
        "        if print_:\n",
        "            self.display()\n",
        "\n",
        "        #The TD error\n",
        "        current_state_value = self.chooseMaxAction(self.agent.state)[1]\n",
        "        last_state_value = self.getValue(list(self.agent.previousState), self.recommendation)\n",
        "        delta = self.agent.reward + self.gamma * current_state_value - last_state_value\n",
        "\n",
        "        #Finally, the gradient descent update\n",
        "        self.weights = self.weights + self.lr*delta*np.array(self.getInput(list(self.agent.previousState), self.recommendation)).reshape(self.n_inputs,1)\n",
        "\n",
        "    def endEpisode(self):\n",
        "        self.recommendation = []\n",
        "\n",
        "    def display(self, print_actions = False):\n",
        "        print(\"--------------------------> Q learning (simple Linear approximation) method :\")\n",
        "        print(\" memory: \" + str(self.memory))\n",
        "        print(\" number of items to recommend at each step : \" + str(self.n_recommended))\n",
        "        print(\" learning rate: \"+str(self.lr))\n",
        "        print(\" gamma: \"+str(self.gamma))\n",
        "        print(\"Weights: \")\n",
        "        print(self.weights)\n",
        "        if print_actions:\n",
        "            print(self.actions)\n",
        "\n",
        "#Helper functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNh-z0zstD3r",
        "colab_type": "text"
      },
      "source": [
        "## Q-Learning (Deep) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DtKZNyvtHMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In this file, we implement the Qlearning method, but using function approximation.\n",
        "#This is a neural network. The trainable parameters are the bias and weight tensor of each \"trainable\" layer\n",
        "# state - action values .\n",
        "# off-policy TD control\n",
        "#Mathematical understanding/formula used : we can have a look at https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Same thing than the Qlearning class, but with more complex actions.\n",
        "#Indeed, before, one action was one item, now an action is a tuple (of all the recommended items).\n",
        "class DeepQlearning():\n",
        "    #items_size is the number of items, memory the \"memory\" hyperparameter to define the states.\n",
        "    def __init__(self, agent,  N_items, Memory, N_recommended, epsilon = 0.1 ,learning_rate = 0.7, gamma = 0.3, choiceMethod = \"eGreedy\", optimize_time = True):\n",
        "        self.n_recommended = N_recommended\n",
        "        self.memory = Memory\n",
        "        self.n_items = N_items\n",
        "        self.n_inputs = self.memory + 2*self.n_recommended\n",
        "        self.agent = agent\n",
        "        self.actions, self.actions_ids = self.initActions()\n",
        "        self.numActions = len(self.actions_ids)\n",
        "        self.lr = learning_rate\n",
        "        self.choiceMethod = choiceMethod\n",
        "        self.epsilon = epsilon\n",
        "        self.gamma = gamma\n",
        "        self.recommendation =  [] #will be updated  (the id of the choice)\n",
        "\n",
        "        # Last minute upgrade to optimize computation time\n",
        "        self.last_5_states = None\n",
        "        self.last_5_states_values = None\n",
        "        if optimize_time:\n",
        "            self.last_5_states = [] #In this list is kept the 5 last visited items\n",
        "            self.last_5_states_values = []  #In this list is kept the values of the 5 last visited items\n",
        "\n",
        "\n",
        "    def setModel(self, Model,Trainable_layers): #A separate step, so that we can have the input size from the Qlearning __init__\n",
        "        self.model = Model\n",
        "        self.trainable_layers = Trainable_layers\n",
        "          # For instance, Qtable[0][5][3] would allow us to get the list of values for actions, for the state [0,5,3] (if memory = 3)\n",
        "\n",
        "\n",
        "    def chooseAction(self, train_): #When we are in a new state, we get to choose a new action\n",
        "        if train_ : #a training session : we choose the choice method specific to training sessions\n",
        "            if self.choiceMethod == \"eGreedy\" :\n",
        "                self.chooseActionEGreedy()\n",
        "            else:\n",
        "                print(\"Error : Qlearning Choice Method not recognized\")\n",
        "        else: #not a training session\n",
        "            self.recommendation = self.chooseMaxAction(self.agent.state)[0]\n",
        "        self.recommendation_id = self.actions.index(self.recommendation)\n",
        "\n",
        "    def chooseActionEGreedy(self):\n",
        "        self.recommendation = []\n",
        "        rand_ = random.random()\n",
        "        if rand_ <= self.epsilon:\n",
        "            self.recommendation = self.chooseMaxAction(self.agent.state)[0]\n",
        "            self.chooseActionRandom()\n",
        "        else:\n",
        "            self.recommendation = self.chooseMaxAction(self.agent.state)[0]\n",
        "\n",
        "\n",
        "\n",
        "    def chooseActionRandom(self):\n",
        "        #We already have chosen the recommendation, according to the \"chooseMaxAction\" function.\n",
        "        # But one of the items is going to be changed, so that it can be chosen randomly.\n",
        "        random_recommendation = np.random.randint(0, self.n_items)\n",
        "        while self.agent.environnement.customer.choice_id == random_recommendation or random_recommendation in self.recommendation:\n",
        "            random_recommendation = np.random.randint(0, self.n_items)\n",
        "        index = np.random.randint(0,self.n_recommended)\n",
        "        self.recommendation[index] = random_recommendation\n",
        "\n",
        "\n",
        "    def initActions(self): #helper function to compute the actions possibilities\n",
        "        def computeActions(n,li):\n",
        "            if n==1 :\n",
        "                return li\n",
        "            else :\n",
        "                li = [prev+ [j] for prev in li for j in self.agent.environnement.items.ids if j not in prev ]\n",
        "                return computeActions(n-1, li)\n",
        "\n",
        "        actions = computeActions(self.n_recommended,[[i] for i in self.agent.environnement.items.ids] )\n",
        "        return (actions,[i for i in range(len(actions))])\n",
        "\n",
        "\n",
        "    def chooseMaxAction(self, state):\n",
        "        #This function could be improved in order to be \"parallelized\", or more efficient.\n",
        "        #However, this work is mainly for theoritical study, we are letting aside the\n",
        "        # 'efficiency' aspect of the code for the moment\n",
        "        current_item = self.agent.environnement.customer.choice_id\n",
        "        best_indice = None\n",
        "        best_value = -np.inf\n",
        "\n",
        "\n",
        "        for i in self.actions_ids:\n",
        "            action = self.actions[i][:]\n",
        "            if current_item not in action:\n",
        "                value = self.getValue(state,action)\n",
        "                if value > best_value:\n",
        "                    best_indice = i\n",
        "                    best_value = value\n",
        "        return  self.actions[best_indice][:] , best_value\n",
        "\n",
        "\n",
        "    def getValue(self,state,action):\n",
        "        input = np.array(self.getInput(state, action))#/self.n_items  #Normalization step : to change in order to get something consistent with when the dataset will be updated\n",
        "        input_tensor = torch.from_numpy(input).float()\n",
        "        output_value = self.model(input_tensor)\n",
        "        #print(output_value, state, action)\n",
        "        return output_value.tolist()[0]\n",
        "\n",
        "        # Here we \"transform\" the input in order to get costs and similarities, instead of item id, as an input\n",
        "        # TODO : see why the basic item_id inputs was not working at all\n",
        "    def getInput(self, state, action):\n",
        "        input = []\n",
        "        # Adding costs of states in memory:\n",
        "        for item_id in state:\n",
        "            input.append(self.agent.environnement.items.items[item_id].cost)\n",
        "        # Adding costs of items of the action:\n",
        "        for item_id in action:\n",
        "            input.append(self.agent.environnement.items.items[item_id].cost)\n",
        "        # Adding similarities of the last state with all items in action\n",
        "        for item_id in action:\n",
        "            input.append(self.agent.environnement.items.similarities[state[-1]][item_id])\n",
        "        # print(state,action,  input)\n",
        "        return input\n",
        "\n",
        "\n",
        "    def getStateOnlyValue(self, state): # Helper function to diminish the training time .\n",
        "        #Indeed, we will use self.values_of_last_5_states to avoid a few for loops\n",
        "        #The randomness with 0.7 ensures that the state value is often upgraded.\n",
        "        #Note that this value can be changed\n",
        "        if random.random() < 0.7 and str(state) in self.last_5_states :\n",
        "            state_value =  self.last_5_states_values[self.last_5_states.index(str(state))]\n",
        "        else :\n",
        "            state_value = self.chooseMaxAction(self.agent.state)[1]\n",
        "        return state_value\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        #The TD error\n",
        "        #current_state_value = self.chooseMaxAction(self.agent.state)[1]\n",
        "        current_state_value = self.getStateOnlyValue(self.agent.state)\n",
        "        if self.last_5_states != None: #\n",
        "            self.last_5_states.append(self.agent.state)\n",
        "            self.last_5_states_values.append(current_state_value)\n",
        "            if len(self.last_5_states) >= 5 :\n",
        "                self.last_5_states_values.pop(0)\n",
        "                self.last_5_states.pop(0)\n",
        "\n",
        "        last_state_value = self.getValue(list(self.agent.previousState), self.recommendation)\n",
        "        delta = self.agent.reward + self.gamma * current_state_value - last_state_value\n",
        "\n",
        "        #Computing the gradients -----------------------------------\n",
        "        X = np.array(self.getInput(list(self.agent.previousState), self.recommendation))\n",
        "        X_tensor = torch.from_numpy(X).float()\n",
        "        y_pred = self.model(X_tensor)\n",
        "        loss = self.value_loss(y_pred)\n",
        "        loss.backward()\n",
        "        #nn.utils.clip_grad_value_(self.model.parameters(), 5)\n",
        "        #Gradient computed -----------------------------------------\n",
        "\n",
        "        # Finally, the gradient descent update\n",
        "        for i in self.trainable_layers:\n",
        "            #Clip gradients\n",
        "            self.model[i].weight.grad.data.clamp_(-0.1,0.1)\n",
        "            self.model[i].bias.grad.data.clamp_(-0.1, 0.1)\n",
        "\n",
        "           # print(\"LAyer \"+str(i))\n",
        "           # print(\"Before\")\n",
        "           # print(self.model[i].weight.data)\n",
        "           # print(self.model[i].bias.data)\n",
        "\n",
        "           # print(\"------------delta, lr & grads ---------------\")\n",
        "           # print(\"delta: \"+str(delta)+\" , lr: \"+str(self.lr))\n",
        "           # print(\"GRADIENTS:\")\n",
        "           # print(self.model[i].weight.grad.data)\n",
        "           # print(self.model[i].bias.grad.data)\n",
        "           # print(\" >>>>>>>>> UPDATE AMOUNT <<<<<<<<<<<\")\n",
        "           # print(self.lr * delta * self.model[i].weight.grad.data)\n",
        "           # print(self.lr * delta * self.model[i].bias.grad.data)\n",
        "           # print(\"---------------------------\")\n",
        "\n",
        "            self.model[i].weight.data = self.model[i].weight.data + self.lr * delta * self.model[i].weight.grad.data\n",
        "            self.model[i].bias.data = self.model[i].bias.data + self.lr * delta * self.model[i].bias.grad.data\n",
        "            self.model[i].weight.grad.data.zero_()\n",
        "            self.model[i].bias.grad.data.zero_()\n",
        "\n",
        "            #print(\"After\")\n",
        "            #print(self.model[i].weight.data)\n",
        "            #print(self.model[i].bias.data)\n",
        "\n",
        "\n",
        "\n",
        "    def value_loss(self,X): #This is the \"loss function\" used by torch to backpropagate (as X will be the score)\n",
        "        return X\n",
        "\n",
        "    def endEpisode(self):\n",
        "        self.recommendation = []\n",
        "\n",
        "    def display(self, print_weights_bias = True,print_actions = False):\n",
        "        print(\"--------------------------> Q learning ( neural network approximation) method :\")\n",
        "        print(\" memory: \" + str(self.memory))\n",
        "        print(\" number of items to recommend at each step : \" + str(self.n_recommended))\n",
        "        print(\" learning rate: \"+str(self.lr))\n",
        "        print(\" gamma: \"+str(self.gamma))\n",
        "        print(\"trainable layers ids: \"+str(self.trainable_layers))\n",
        "        print(\"Model:\")\n",
        "        print(self.model)\n",
        "        if print_weights_bias:\n",
        "            for i in self.trainable_layers:\n",
        "                print('\\n <---- Weight and bias of Layer ' + str(i) + ' ---->')\n",
        "                print(\"Weight -->\")\n",
        "                print(self.model[i].weight.data)\n",
        "                print('Bias -->')\n",
        "                print(self.model[i].bias.data)\n",
        "        if print_actions:\n",
        "            print(self.actions)\n",
        "        print('----------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM7yVlygVYSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Same thing than the Qlearning class, but with more complex actions.\n",
        "#Indeed, before, one action was one item, now an action is a tuple (of all the recommended items).\n",
        "class QlearningActionTuples():\n",
        "    #items_size is the number of items, memory the \"memory\" hyperparameter to define the states.\n",
        "    def __init__(self, agent, items_size, memory, N_recommended,epsilon = 0.1 ,learning_rate = 0.7, gamma = 0.3, choiceMethod = \"eGreedy\"):\n",
        "        self.N_recommended = N_recommended\n",
        "        self.agent = agent\n",
        "        self.actions, self.actions_ids = self.initActions()\n",
        "        self.numActions = len(self.actions_ids)\n",
        "        self.dims =  [items_size for i in range(memory)]+[self.numActions] #the +1 for the actions\n",
        "        self.initQtable()\n",
        "        self.lr = learning_rate\n",
        "        self.choiceMethod = choiceMethod\n",
        "        self.epsilon = epsilon\n",
        "        self.gamma = gamma\n",
        "        self.recommendation =  [] #will be updated  (the id of the choice)\n",
        "\n",
        "\n",
        "    def initActions(self): #helper function to compute the actions possibilities\n",
        "        def computeActions(n,li):\n",
        "            if n==1 :\n",
        "                return li\n",
        "            else :\n",
        "                li = [prev+ [j] for prev in li for j in self.agent.environnement.items.ids if j not in prev ]\n",
        "                return computeActions(n-1, li)\n",
        "\n",
        "        actions = computeActions(self.N_recommended,[[i] for i in self.agent.environnement.items.ids] )\n",
        "        return (actions,[i for i in range(len(actions))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def initQtable(self): #We have to initialize the Qtable (and remove the possibility of recommending the currently watched item)\n",
        "        #self.Qtable = np.ones(self.dims)  # not flattened Qtable. Optimistic values (ones) to encourage exploration at the beginning.\n",
        "        #self.Qtable = np.ones(self.dims)\n",
        "        # Or we can also set everything to 0\n",
        "        self.Qtable = np.zeros(self.dims)\n",
        "        for lastState in range(self.dims[-2]):\n",
        "            for action_id in self.actions_ids :\n",
        "                if lastState in self.actions[action_id]:\n",
        "                    self.Qtable[..., lastState, action_id] = -np.inf\n",
        "\n",
        "\n",
        "        # For instance, Qtable[0][5][3] would allow us to get the list of values for actions, for the state [0,5,3] (if memory = 3)\n",
        "\n",
        "    def chooseAction(self, train_): #When we are in a new state, we get to choose a new action\n",
        "        if train_ : #a training session : we choose the choice method specific to training sessions\n",
        "            if self.choiceMethod == \"eGreedy\" :\n",
        "                self.chooseActionEGreedy()\n",
        "            else:\n",
        "                print(\"Error : Qlearning Choice Method not recognized\")\n",
        "        else: #not a training session\n",
        "            self.recommendation_id = self.chooseMaxAction(self.agent.state, 1)[0]\n",
        "            self.recommendation = self.actions[self.recommendation_id]\n",
        "\n",
        "\n",
        "    def chooseActionEGreedy(self):\n",
        "        self.recommendation = []\n",
        "        rand_ = random.random()\n",
        "        if rand_ <= self.epsilon:\n",
        "            self.chooseActionRandom()\n",
        "\n",
        "        else:\n",
        "            self.recommendation_id = self.chooseMaxAction(self.agent.state, 1)[0]\n",
        "            self.recommendation = self.actions[self.recommendation_id]\n",
        "\n",
        "\n",
        "    def chooseActionRandom(self):\n",
        "        recommendation_id = np.random.choice(self.actions_ids)\n",
        "        while self.agent.environnement.customer.choice_id in self.actions[recommendation_id]:\n",
        "            recommendation_id = np.random.choice(self.actions_ids)\n",
        "        self.recommendation_id = recommendation_id\n",
        "        self.recommendation = self.actions[self.recommendation_id][:]\n",
        "\n",
        "\n",
        "    # def chooseActionRandomLast(self):\n",
        "    #     maxChoices = self.chooseMaxAction(self.agent.state, self.N_recommended - 1)\n",
        "    #     randomChoice = np.random.choice(self.agent.environnement.items.ids[:self.agent.environnement.customer.choice_id]+self.agent.environnement.items.ids[self.agent.environnement.customer.choice_id + 1:],1, replace=False)\n",
        "    #     while randomChoice in maxChoices :\n",
        "    #         randomChoice = np.random.choice(self.agent.environnement.items.ids[:self.agent.environnement.customer.choice_id] + self.agent.environnement.items.ids[self.agent.environnement.customer.choice_id + 1:],1, replace=False)\n",
        "    #     self.recommendation = maxChoices[:].tolist()\n",
        "    #     self.recommendation.append(randomChoice[0])\n",
        "\n",
        "\n",
        "    #(We need to update this function to add randomness! (not select the n_recommended higher in the order of their id...)\n",
        "    def chooseMaxAction(self, state, num):\n",
        "       # self.Qtable[tuple(state)][state[-1]] = -np.inf  #to make sure we wont recommend the currently watched item\n",
        "        #return (np.flip(self.Qtable[tuple(state)]).argsort()[- num :])\n",
        "        return self.selectRandomlyMax(np.copy(self.Qtable[tuple(state)][:]), num, [])\n",
        "\n",
        "    def train(self, print_ = False):   #/!\\ to update\n",
        "        if print_:\n",
        "            self.display()\n",
        "\n",
        "        prev_state_reco = self.Qtable[tuple(self.agent.previousState)][self.recommendation_id]\n",
        "        current_state_max = self.Qtable[tuple(self.agent.state)][self.chooseMaxAction(self.agent.state, 1)][0]\n",
        "        self.Qtable[tuple(self.agent.previousState)][self.recommendation_id] = prev_state_reco + self.lr * (self.agent.reward + self.gamma * current_state_max - prev_state_reco)\n",
        "\n",
        "\n",
        "\n",
        "    def endEpisode(self):\n",
        "        self.recommendation = []\n",
        "\n",
        "    def display(self):\n",
        "        print(\"--------------------------> Q learning (tuple actions) method :\")\n",
        "        print(\" learning rate: \"+str(self.lr))\n",
        "        print(\" gamma: \"+str(self.gamma))\n",
        "        print(\">>>>> Qtable <<<<<\")\n",
        "        print(self.Qtable)\n",
        "\n",
        "\n",
        "#Helper functions :\n",
        "\n",
        "\n",
        "    def selectRandomlyMax(self, li, n, results): #select randomly n maximums in an np.array list. Returns indices.\n",
        "        if n == 0:\n",
        "            return np.array(results)\n",
        "        else :\n",
        "            max_ = np.max(li)\n",
        "            ind = np.argwhere(li == max_).flatten()\n",
        "            choice = np.random.choice(ind)\n",
        "            results.append(choice)\n",
        "            li[choice] = -np.inf\n",
        "            return self.selectRandomlyMax(li, n-1, results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrekdphptxht",
        "colab_type": "text"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKn-OIj1uKKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "    def __init__(self, environnement, memory ,  choiceMethod ,  params, name = 'toto_01' ): #memory is an hyper parameter.\n",
        "        self.environnement = environnement\n",
        "        self.N_recommended = environnement.recommendation.n_recommended\n",
        "        self.memory = memory\n",
        "        self.state = []   #In this stack we remember the #memory last choices of the user\n",
        "        self.previousState = []\n",
        "        self.reward = 0 #reward at each step\n",
        "        self.totalReward = 0#Total reward after an episode\n",
        "        self.init_State()\n",
        "        self.choiceMethod = choiceMethod #This defines how the Agent promotes new recommendations at each time\n",
        "        self.recommendation = []\n",
        "        self.name = name\n",
        "\n",
        "\n",
        "        if self.choiceMethod == 'Qlearning':\n",
        "            QLchoiceMethod = params['QLchoiceMethod']\n",
        "            epsilon = params['epsilon']\n",
        "            learning_rate = params['learning_rate']\n",
        "            gamma = params['gamma']\n",
        "            self.Qlearning = Qlearning(self, self.environnement.items.n_items, memory, self.N_recommended,epsilon  ,learning_rate , gamma, QLchoiceMethod )\n",
        "\n",
        "\n",
        "        elif self.choiceMethod == 'QlearningActionsTuples':\n",
        "            QLchoiceMethod = params['QLchoiceMethod']\n",
        "            epsilon = params['epsilon']\n",
        "            learning_rate = params['learning_rate']\n",
        "            gamma = params['gamma']\n",
        "            self.Qlearning = QlearningActionTuples(self, self.environnement.items.n_items, memory, self.N_recommended,epsilon  ,learning_rate , gamma, QLchoiceMethod )\n",
        "            self.choicesThisEpisode = np.zeros(self.Qlearning.numActions)\n",
        "\n",
        "        elif self.choiceMethod == 'LinearQlearning':\n",
        "            QLchoiceMethod = params['QLchoiceMethod']\n",
        "            epsilon = params['epsilon']\n",
        "            learning_rate = params['learning_rate']\n",
        "            gamma = params['gamma']\n",
        "            self.Qlearning = LinearQlearning(self, self.environnement.items.n_items, memory, self.N_recommended,\n",
        "                                                   epsilon, learning_rate, gamma, QLchoiceMethod)\n",
        "            self.choicesThisEpisode = np.zeros(self.Qlearning.numActions)\n",
        "\n",
        "        elif self.choiceMethod == 'PolynomialQlearning':\n",
        "            QLchoiceMethod = params['QLchoiceMethod']\n",
        "            epsilon = params['epsilon']\n",
        "            learning_rate = params['learning_rate']\n",
        "            gamma = params['gamma']\n",
        "            degree = params['degree']\n",
        "            self.Qlearning = PolynomialQlearning(self, degree, self.environnement.items.n_items, memory, self.N_recommended,\n",
        "                                             epsilon, learning_rate, gamma, QLchoiceMethod)\n",
        "            self.choicesThisEpisode = np.zeros(self.Qlearning.numActions)\n",
        "\n",
        "        elif self.choiceMethod == 'SimpleDeepQlearning':\n",
        "            QLchoiceMethod = params['QLchoiceMethod']\n",
        "            epsilon = params['epsilon']\n",
        "            learning_rate = params['learning_rate']\n",
        "            gamma = params['gamma']\n",
        "            hidden_size = params['hidden_size']\n",
        "            self.Qlearning = SimpleDeepQlearning(self, hidden_size, self.environnement.items.n_items, memory,\n",
        "                                                 self.N_recommended,\n",
        "                                                 epsilon, learning_rate, gamma, QLchoiceMethod)\n",
        "            self.choicesThisEpisode = np.zeros(self.Qlearning.numActions)\n",
        "\n",
        "        elif self.choiceMethod == 'DeepQlearning':\n",
        "            QLchoiceMethod = params['QLchoiceMethod']\n",
        "            epsilon = params['epsilon']\n",
        "            learning_rate = params['learning_rate']\n",
        "            gamma = params['gamma']\n",
        "            self.Qlearning = DeepQlearning(self,  self.environnement.items.n_items, memory,\n",
        "                                                 self.N_recommended,\n",
        "                                                 epsilon, learning_rate, gamma, QLchoiceMethod)\n",
        "            self.choicesThisEpisode = np.zeros(self.Qlearning.numActions)\n",
        "\n",
        "        elif self.choiceMethod == 'DeepQlearningFaster':\n",
        "            QLchoiceMethod = params['QLchoiceMethod']\n",
        "            epsilon = params['epsilon']\n",
        "            learning_rate = params['learning_rate']\n",
        "            gamma = params['gamma']\n",
        "            debug = params['debug']\n",
        "            subset_size = params['subset_size']\n",
        "\n",
        "            self.Qlearning = DeepQlearningFaster(self,  self.environnement.items.n_items, memory,\n",
        "                                                 self.N_recommended,subset_size,\n",
        "                                                 epsilon, learning_rate, gamma, QLchoiceMethod, debug = debug)\n",
        "\n",
        "            self.choicesThisEpisode = np.zeros(self.Qlearning.numActions)\n",
        "\n",
        "\n",
        "\n",
        "    def init_State(self): #In order to still be able to make a recommendation at the begining (when the customer made no choice yet)\n",
        "        li = [self.environnement.customer.previous_choice_id, self.environnement.customer.choice_id]\n",
        "        for i in range(self.memory-2):\n",
        "           # self.state.append(-1) #Means that nothing was chosen at the beginning old false version\n",
        "           random_ = random.randint(0, self.environnement.items.n_items-1)\n",
        "           while random_ == li[0]:\n",
        "               random_ = random.randint(0, self.environnement.items.n_items-1)\n",
        "           li = [random_] + li\n",
        "\n",
        "        if self.memory == 1 :\n",
        "            self.state = [self.environnement.customer.choice_id]\n",
        "        else:\n",
        "            self.state = li\n",
        "\n",
        "    def updateStateAndReward(self, reward): #will help update the state at each step\n",
        "        #keep previous values in case we want to train\n",
        "        self.previousState = np.copy(self.state)\n",
        "\n",
        "        self.state[:-1] = self.state[1:]\n",
        "        self.state[-1] = self.environnement.customer.choice_id\n",
        "        self.reward = reward\n",
        "        self.totalReward += reward\n",
        "\n",
        "    def recommend(self, train_=False):#\n",
        "        if self.choiceMethod == \"random\" :\n",
        "            self.recommendation = np.random.choice(self.environnement.items.ids[:self.environnement.customer.choice_id]+self.environnement.items.ids[self.environnement.customer.choice_id+1:],self.N_recommended, replace= False)\n",
        "        elif self.choiceMethod == \"Qlearning\"  :\n",
        "            self.Qlearning.chooseAction()\n",
        "            self.recommendation = self.Qlearning.recommendation\n",
        "        elif self.choiceMethod in [\"QlearningActionsTuples\", \"LinearQlearning\",\"PolynomialQlearning\", \"SimpleDeepQlearning\", \"DeepQlearning\",\"DeepQlearningFaster\"]:\n",
        "            self.Qlearning.chooseAction(train_)\n",
        "            self.recommendation = self.Qlearning.recommendation\n",
        "            self.choicesThisEpisode[self.Qlearning.recommendation_id] += 1\n",
        "        else :\n",
        "            print('Error : choiceMethod not recognized in agent.recommend() function')\n",
        "\n",
        "    def train(self):\n",
        "        if self.choiceMethod != 'random' :\n",
        "            self.Qlearning.train()\n",
        "\n",
        "    def endEpisode(self):\n",
        "        self.totalReward = 0\n",
        "        self.reward = 0\n",
        "        self.state = []  # In this stack we remember the #memory last choices of the user\n",
        "        self.previousState = []\n",
        "        self.init_State()\n",
        "        self.recommendation = []\n",
        "        if self.choiceMethod != \"random\" and self.choiceMethod != \"Qlearning\":\n",
        "            self.choicesThisEpisode = np.zeros(self.Qlearning.numActions)\n",
        "            self.Qlearning.endEpisode()\n",
        "        else:\n",
        "            self.Qlearning.endEpisode()\n",
        "\n",
        "    def display(self):\n",
        "        print(\"------ AGENT DISPLAY ------\")\n",
        "        #print(\"*** Previous State ***\")\n",
        "        #print(self.previousState)\n",
        "        print(\"*** Current State ***\")\n",
        "        print(self.state)\n",
        "        print(\"*** Recommendation ***\")\n",
        "        print(self.recommendation)\n",
        "        print(\"Current reward: \"+str(self.reward))\n",
        "        print(\"Total reward: \"+ str(self.totalReward))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yceyHpSX-vKi",
        "colab_type": "text"
      },
      "source": [
        "## Episode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twUUxM3S_Sby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Episode():\n",
        "    def __init__(self, environnement, agent, steps = 10, train_ = False, display = False, displayItems  = False):\n",
        "        self.environnement = environnement\n",
        "        self.agent = agent\n",
        "        self.train_ = train_\n",
        "        self.agent.init_State()\n",
        "\n",
        "        if display:\n",
        "            print(\">>>>>>>>>>>>>>>>> Episode  <<<<<<<<<<<<<<<<<\")\n",
        "            print('Length of the episode : '+str(steps))\n",
        "            print('Agent name : '+self.agent.name+' , Method: '+self.agent.choiceMethod)\n",
        "            print('Environnement name: '+self.environnement.name)\n",
        "            self.environnement.display(displayItems)\n",
        "            self.agent.display()\n",
        "\n",
        "        for step in range(steps):\n",
        "            self.step()  # new step of the environnement and agent\n",
        "            if display:\n",
        "                print(\">>>>>>>>>> STEP \"+str(step)+\":\")\n",
        "                self.agent.display()\n",
        "                self.environnement.customer.display()\n",
        "        if display:\n",
        "            print(\"List of the recommender choices:\")\n",
        "            print(self.environnement.recommendation.choicesThisEpisode)\n",
        "            print(\"List of the choices of the customer :\")\n",
        "            print(self.environnement.customer.choicesThisEpisode)\n",
        "            print(\">>>>>>>>>>>>>> end  <<<<<<<<<<<<<<\")\n",
        "\n",
        "        #________________ Ending the episode : keep the total reward andreinitialize the agent\n",
        "      #  print(\"WWWWWW\" +str(self.environnement.recommendation.choicesThisEpisode))\n",
        "       # print(self.environnement.customer.choicesThisEpisode)\n",
        "        self.choicesThisEpisode = self.environnement.recommendation.choicesThisEpisode[:]\n",
        "        if self.agent.choiceMethod != \"random\" and self.agent.choiceMethod != \"Qlearning\":\n",
        "            self.choicesThisEpisodeActionTuples = self.agent.choicesThisEpisode[:]\n",
        "        self.episodeReward = self.agent.totalReward #We will\n",
        "        self.agent.endEpisode()\n",
        "        self.environnement.endEpisode()\n",
        "\n",
        "\n",
        "\n",
        "    def step(self):\n",
        "        if self.agent.choiceMethod != \"random\" and self.agent.choiceMethod != \"Qlearning\":\n",
        "            self.agent.recommend(self.train_)\n",
        "        else :  #/!\\ temporary : all agents should in the end also only choose the actions with maw value in non train mode\n",
        "            self.agent.recommend()\n",
        "\n",
        "        reward = self.environnement.step(self.agent.recommendation)\n",
        "        self.agent.updateStateAndReward(reward)\n",
        "        if self.train_ :\n",
        "            self.agent.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EQmPH_x-7yC",
        "colab_type": "text"
      },
      "source": [
        "## Series of episodes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH2xVHLW_Ywh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageSeries(): #Helpful to get a better unbiased statistical estimate of the efficiency of our model\n",
        "    #We redo the learning process several times and average the results to reduce the amount of randomness in our results\n",
        "\n",
        "    def __init__(self, num_avg, environnement, memory, choiceMethod, params, epochs, train_list, steps=5,deepQModel = None, display=True  ):\n",
        "\n",
        "        self.choicesLastSerie_total = np.zeros(environnement.items.n_items)\n",
        "\n",
        "        if display:\n",
        "            startTime = time.time()\n",
        "            print(\"------------------> Average of series begins:  <------------------\")\n",
        "            print(str(num_avg)+\" independent training/testing processes\")\n",
        "            print(\"environnement name: \"+environnement.name)\n",
        "            print(\"Memory size: \" + str(memory))\n",
        "            print(\"Number of items to recommend: \"+ str(environnement.recommendation.n_recommended))\n",
        "            print(\"--- We will test the following hyperparameters ---\")\n",
        "            print(\"choice method: \" + choiceMethod)\n",
        "            print(\"epochs: \"+ str(epochs))\n",
        "            print(\"Reward hyper parameters: \"+ str(environnement.rewardParameters))\n",
        "            if choiceMethod != \"random\" :\n",
        "                print(params)\n",
        "\n",
        "\n",
        "        agent = Agent(environnement, memory, choiceMethod, params)\n",
        "        #if enableDebug : #It means that we want to visualize the actions for the DeepQlearningFaster model:\n",
        "         #   agent.Qlearning.setDebugMode()\n",
        "\n",
        "        if choiceMethod == \"DeepQlearning\" or choiceMethod == \"DeepQlearningFaster\":\n",
        "            agent.Qlearning.setModel(copy.deepcopy(deepQModel['model']), deepQModel['trainable_layers'])\n",
        "\n",
        "\n",
        "\n",
        "        series = Series(environnement, agent, epochs, train_list, steps)\n",
        "\n",
        "\n",
        "\n",
        "        self.avgRewards = np.array(series.allRewards[:])\n",
        "        if choiceMethod != \"random\" and choiceMethod != \"Qlearning\" : #as Qlearning is an old version\n",
        "            self.choicesLastSerieActionTuples_total = np.zeros(agent.Qlearning.numActions)\n",
        "\n",
        "        for a in tqdm(range(num_avg - 1)):\n",
        "            # We keep the exact same environnement, but reinitialize the Q-table (testing if we were just lucky in the learning process)\n",
        "            agent = Agent(environnement, memory, choiceMethod, params)\n",
        "\n",
        "            #DeepQlearning setup --------------------------------------------------------------\n",
        "            if choiceMethod == \"DeepQlearning\" or choiceMethod == \"DeepQlearningFaster\" :\n",
        "                agent.Qlearning.setModel(copy.deepcopy(deepQModel['model']), deepQModel['trainable_layers'])\n",
        "            #----------------------------------------------------------------------------------\n",
        "            #print(\"-------------------- BEFORE ----------------------------------\")\n",
        "            #agent.Qlearning.display()  # TODO : remove the print\n",
        "            series = Series(environnement, agent, epochs, train_list, steps)\n",
        "           # print(\"-------------------- AFTER -----------------------------------\")\n",
        "            #agent.Qlearning.display()  # TODO : remove the print\n",
        "            self.avgRewards =  self.avgRewards  +  np.array(series.allRewards[:])\n",
        "            self.choicesLastSerie_total= self.choicesLastSerie_total + series.choicesLastSerie\n",
        "\n",
        "            if choiceMethod != \"random\" and choiceMethod != \"Qlearning\" :\n",
        "                self.choicesLastSerieActionTuples_total = self.choicesLastSerieActionTuples_total + series.choiceslastSerieActionTuples\n",
        "\n",
        "\n",
        "        self.avgRewards = self.avgRewards/num_avg\n",
        "        self.avgLastReward = self.avgRewards[-1]\n",
        "\n",
        "        #print(\"steps \"+str(steps)+\" AVGSerieS-reward \" + str(self.avgRewards) )\n",
        "\n",
        "        if display:\n",
        "            endTime = time.time()\n",
        "            print(\" \\n \\n Execution time: \"+str(endTime - startTime))\n",
        "\n",
        "\n",
        "            if choiceMethod == \"QlearningActionsTuples\":\n",
        "                print(\"Qtable of the last series ------------------------------>\")\n",
        "                print(agent.Qlearning.Qtable)\n",
        "                print(\"---------------------------------------------------->\")\n",
        "                print(\" \")\n",
        "                print(\"After the learning process : how often  is an item recommended? (total of all series) \")\n",
        "                print(self.choicesLastSerie_total)\n",
        "                print(\"After the learning process : how often  is an Action tuple recommended? (total of all series) \")\n",
        "                print(\"Action list:\")\n",
        "                print(agent.Qlearning.actions)\n",
        "                print(\"Action ids list:\")\n",
        "                print(agent.Qlearning.actions_ids)\n",
        "                print(\"Number of time selected (per action id):\")\n",
        "                print(self.choicesLastSerieActionTuples_total)\n",
        "                print(\"Most recommended action: \" + str(agent.Qlearning.actions[np.argmax(np.array(self.choicesLastSerieActionTuples_total))]))\n",
        "\n",
        "            elif choiceMethod == \"LinearQlearning\":\n",
        "                print(\"Final weights: \")\n",
        "                print(agent.Qlearning.weights)\n",
        "                print(\"Action list:\")\n",
        "                print(agent.Qlearning.actions)\n",
        "                print(\"Action ids list:\")\n",
        "                print(agent.Qlearning.actions_ids)\n",
        "                print(\"Number of time selected (per action id):\")\n",
        "                print(self.choicesLastSerieActionTuples_total)\n",
        "                print(\"Most recommended action: \"+str(agent.Qlearning.actions[np.argmax(np.array(self.choicesLastSerieActionTuples_total))]))\n",
        "\n",
        "            elif  choiceMethod == \"PolynomialQlearning\":\n",
        "                print(\"Final weights: \")\n",
        "                print(agent.Qlearning.weights)\n",
        "                print(\"Action list:\")\n",
        "                print(agent.Qlearning.actions)\n",
        "                print(\"Action ids list:\")\n",
        "                print(agent.Qlearning.actions_ids)\n",
        "                print(\"Number of time selected (per action id):\")\n",
        "                print(self.choicesLastSerieActionTuples_total)\n",
        "                print(\"Most recommended action: \" + str(agent.Qlearning.actions[np.argmax(np.array(self.choicesLastSerieActionTuples_total))]))\n",
        "\n",
        "            elif choiceMethod == \"SimpleDeepQlearning\":\n",
        "                print(\">>> Final weights: \")\n",
        "                print(\"Hidden weights\")\n",
        "                print(agent.Qlearning.weights1)\n",
        "                print(\"Hidden bias\")\n",
        "                print(agent.Qlearning.bias1)\n",
        "                print(\"Output weights\")\n",
        "                print(agent.Qlearning.weights2)\n",
        "                print(\"Hidden bias\")\n",
        "                print(agent.Qlearning.bias2)\n",
        "                print(\"Action list:\")\n",
        "                print(agent.Qlearning.actions)\n",
        "                print(\"Action ids list:\")\n",
        "                print(agent.Qlearning.actions_ids)\n",
        "                print(\"Number of time selected (per action id):\")\n",
        "                print(self.choicesLastSerieActionTuples_total)\n",
        "                print(\"Most recommended action: \" + str(agent.Qlearning.actions[np.argmax(np.array(self.choicesLastSerieActionTuples_total))]))\n",
        "\n",
        "            elif choiceMethod == \"DeepQlearning\" :\n",
        "                agent.Qlearning.display(True)\n",
        "                print(\"Action list:\")\n",
        "                print(agent.Qlearning.actions)\n",
        "                print(\"Action ids list:\")\n",
        "                print(agent.Qlearning.actions_ids)\n",
        "                print(\"Number of time selected (per action id):\")\n",
        "                print(self.choicesLastSerieActionTuples_total)\n",
        "                print(\"Most recommended action: \" + str(agent.Qlearning.actions[np.argmax(np.array(self.choicesLastSerieActionTuples_total))]))\n",
        "\n",
        "            elif  choiceMethod == \"DeepQlearningFaster\":\n",
        "                agent.Qlearning.display(True)\n",
        "                if agent.Qlearning.debug:\n",
        "                    print(\"Action list:\")\n",
        "                    print(agent.Qlearning.actions)\n",
        "                    print(\"Action ids list:\")\n",
        "                    print(agent.Qlearning.actions_ids)\n",
        "                    print(\"Number of time selected (per action id):\")\n",
        "                    print(self.choicesLastSerieActionTuples_total)\n",
        "                    print(\"Most recommended action: \" + str(agent.Qlearning.actions[np.argmax(np.array(self.choicesLastSerieActionTuples_total))]))\n",
        "                else:\n",
        "                    print(\"Not in debug mode \")\n",
        "                    #print(\"Number of steps in the last serie, per parallel process: \"+str(self.choicesLastSerieActionTuples_total/num_avg))\n",
        "            print(\"------------------> Series ends <------------------\")\n",
        "\n",
        "class Series(): #several series, to show the whole learning/testing process\n",
        "    def __init__(self, environnement, agent, epochs, train_list, steps=5,  display=False):\n",
        "\n",
        "       # print(\"-----------BEGIN\")\n",
        "       # print(agent.Qlearning.weights)\n",
        "\n",
        "        if display:\n",
        "            print(\"------------------> Series begins <------------------\")\n",
        "\n",
        "        self.allRewards = []\n",
        "        for train_ in train_list:\n",
        "            serie = Serie(environnement, agent, epochs, steps, train_, display)\n",
        "           # self.allRewards = self.allRewards + serie.serieRewards[:]\n",
        "            self.allRewards.append(np.mean(serie.serieRewards[:]))\n",
        "        self.choicesLastSerie = serie.choicesThisSerie[:] #Equal to the choices done at the last \"not training\" serie (end of the learning process)\n",
        "        if agent.choiceMethod != \"random\" and agent.choiceMethod != \"Qlearning\":\n",
        "            self.choiceslastSerieActionTuples = serie.choicesThisSerieActionTuples\n",
        "\n",
        "        #print(\"steps \" + str(steps) + \" SerieS-reward \" + str(self.allRewards))\n",
        "        if display:\n",
        "\n",
        "            print(\"------------------> Series ends <------------------\")\n",
        "        #print(\"-----------END\")\n",
        "        #print(agent.Qlearning.weights)\n",
        "\n",
        "\n",
        "class Serie(): #a serie is a serie of episodes with all the same train_ type (true or false).\n",
        "    # train_ indicates if the agent is going to updates its Qtable during the episode (training)\n",
        "    def __init__(self, environnement, agent, epochs, steps = 10, train_ = False, display = False ):\n",
        "        self.serieRewards = []\n",
        "        self.choicesThisSerie = np.zeros(environnement.items.n_items)\n",
        "\n",
        "        if display :\n",
        "            self.display(train_)\n",
        "\n",
        "        if agent.choiceMethod != \"random\" and agent.choiceMethod != \"Qlearning\":\n",
        "            self.choicesThisSerieActionTuples = np.zeros(agent.Qlearning.numActions)\n",
        "\n",
        "        for epoch in range(epochs ):\n",
        "            episode = Episode(environnement, agent, steps, train_)\n",
        "            self.serieRewards.append(np.mean(episode.episodeReward)) #Taking the mean should help get more consistent results\n",
        "            self.choicesThisSerie = self.choicesThisSerie + episode.choicesThisEpisode\n",
        "            if agent.choiceMethod != \"random\" and agent.choiceMethod != \"Qlearning\":\n",
        "                self.choicesThisSerieActionTuples = self.choicesThisSerieActionTuples + episode.choicesThisEpisodeActionTuples\n",
        "\n",
        "        #print(\"steps \"+str(steps)+\" Serie-reward \"+str(self.serieRewards))\n",
        "\n",
        "    def display(self, train_):\n",
        "        print(\"------------------> Serie begins\")\n",
        "        print(\"Training session: \"+str(train_))\n",
        "\n",
        "\n",
        "\n",
        "        #TODO : paragraph that could be a good starting point for cloning model in AverageSeries, in case copy.deepCopy does not work well with python version\n",
        "        #self.model =deepQModel['model']\n",
        "            #self.trainable_layers = deepQModel['trainable_layers']\n",
        "            #Lets keep the model's parameter, in order to get the same initialization at each average:\n",
        "            #self.initial_deepQ_model_values = {}\n",
        "            #for i in self.trainable_layers:\n",
        "                #self.initial_deepQ_model_values['w'+str(i)]  =  self.model[i].weight.data.clone()\n",
        "                #self.initial_deepQ_model_values['b' + str(i)] = self.model[i].bias.data.clone()\n",
        "            #setting the model to the agent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoOgqS5YWPKs",
        "colab_type": "text"
      },
      "source": [
        "## Grid search (hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6rlAeehWUKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Helper function for hyper parameter tuning\n",
        "\n",
        "class GridSearch(): #helper function for hyper parameter tuning\n",
        "    def __init__(self, display = True):\n",
        "        self.display = display\n",
        "\n",
        "\n",
        "    def __call__(self, num_avg, environnement, memory, choiceMethod, epochs, train_list, steps=5, more_params = None, deepQModel =None):\n",
        "\n",
        "        startTime = time.time()\n",
        "\n",
        "        if choiceMethod != \"random\" :\n",
        "            learning_rates = [ 0.001, 0.01, 0.1, 1]\n",
        "            #epsilons = [0.01, 0.05, 0.1, 0.2, 0.4]\n",
        "            epsilons = [ 0.1, 0.2, 0.4]\n",
        "            gammas = [0.1,0.3,0.5,0.7,0.9]\n",
        "\n",
        "\n",
        "  # ----- AVOIDING NAN VALUES or Vanishing gradients ------------------------------------\n",
        "\n",
        "            if choiceMethod == \"SimpleDeepQlearning\":\n",
        "                learning_rates = [ 0.001, 0.01, 0.1]\n",
        "                epsilons = [0.2, 0.4]\n",
        "                gammas = [0.1,  0.5,  0.9]\n",
        "\n",
        "            if choiceMethod == \"DeepQlearning\" or choiceMethod == \"DeepQlearningFaster\":\n",
        "                learning_rates = [1e-3, 1e-2, 1e-1]\n",
        "                epsilons = [0.1,0.3]\n",
        "                gammas = [0.1,  0.5,  0.9]\n",
        "  # --------------------------------------------------------------\n",
        "\n",
        "\n",
        "            params = {\"QLchoiceMethod\": \"eGreedy\",\n",
        "                      \"epsilon\": None,\n",
        "                      \"learning_rate\": None,\n",
        "                      \"gamma\": None}\n",
        "\n",
        "            best_params = {\"QLchoiceMethod\": \"eGreedy\",\n",
        "                           \"epsilon\": None,\n",
        "                           \"learning_rate\": None,\n",
        "                           \"gamma\": None}\n",
        "\n",
        "            if choiceMethod == \"PolynomialQlearning\":\n",
        "                params['degree']= more_params['degree']\n",
        "                best_params['degree'] = more_params['degree']\n",
        "\n",
        "            if choiceMethod == \"SimpleDeepQlearning\" :\n",
        "                params['hidden_size']= more_params['hidden_size']\n",
        "                best_params['hidden_size'] = more_params['hidden_size']\n",
        "\n",
        "            if choiceMethod == \"DeepQlearningFaster\":\n",
        "                params['subset_size'] = more_params['subset_size']\n",
        "                best_params['subset_size'] = more_params['subset_size']\n",
        "                params['debug'] = more_params['debug']\n",
        "                best_params['debug'] = more_params['debug']\n",
        "\n",
        "\n",
        "            best_reward = -np.inf\n",
        "            for lr in tqdm(learning_rates):\n",
        "                #for g in tqdm(gammas):\n",
        "                for g in gammas:\n",
        "                    #for eps in tqdm(epsilons):\n",
        "                    for eps in epsilons:\n",
        "\n",
        "                        #params = {\"QLchoiceMethod\": \"eGreedy\",\n",
        "                         #         \"epsilon\": eps,\n",
        "                          #        \"learning_rate\": lr,\n",
        "                          #        \"gamma\": g}\n",
        "\n",
        "                        params[\"epsilon\"], params['learning_rate'], params['gamma'] = eps,lr,g\n",
        "\n",
        "                        average_series = AverageSeriesNoTqdm(num_avg, environnement, memory, choiceMethod, params, epochs, train_list,\n",
        "                                      steps=steps, deepQModel = deepQModel)\n",
        "\n",
        "                        if average_series.avgLastReward > best_reward:\n",
        "                            best_reward = average_series.avgLastReward\n",
        "                            best_params[\"epsilon\"], best_params['learning_rate'], best_params['gamma'] = eps, lr, g\n",
        "\n",
        "\n",
        "            endTime = time.time()\n",
        "            if self.display:\n",
        "                print(\"******** Grid Search results : *******\")\n",
        "                print(\"best_reward: \"+str(best_reward))\n",
        "                print(\"best parameters \")\n",
        "                print(best_params)\n",
        "                print(\"**************************************\")\n",
        "                print(\" \\n \\n Execution time of grid Search: \" + str(endTime - startTime))\n",
        "\n",
        "            return best_reward, best_params\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AverageSeriesNoTqdm(): #Helpful to get a better unbiased statistical estimate of the efficiency of our model\n",
        "    #We redo the learning process several times and average the results to reduce the amount of randomness in our results\n",
        "\n",
        "    def __init__(self, num_avg, environnement, memory, choiceMethod, params, epochs, train_list, steps=5,deepQModel = None, display = False):\n",
        "\n",
        "        self.choicesLastSerie_total = np.zeros(environnement.items.n_items)\n",
        "        if display:\n",
        "            startTime = time.time()\n",
        "            print(\"------------------> Average of series begins:  <------------------\")\n",
        "            print(str(num_avg)+\" independent training/testing processes\")\n",
        "            print(\"environnement name: \"+environnement.name)\n",
        "            print(\"Memory size: \" + str(memory))\n",
        "            print(\"Number of items to recommend: \"+ str(environnement.recommendation.n_recommended))\n",
        "            print(\"--- We will test the following hyperparameters ---\")\n",
        "            print(\"choice method: \" + choiceMethod)\n",
        "            print(\"epochs: \"+ str(epochs))\n",
        "            print(\"Reward hyper parameters: \"+ str(environnement.rewardParameters))\n",
        "            if choiceMethod != \"random\" :\n",
        "                print(params)\n",
        "\n",
        "        agent = Agent(environnement, memory, choiceMethod, params)\n",
        "        if choiceMethod == \"DeepQlearning\" or choiceMethod == \"DeepQlearningFaster\":\n",
        "            agent.Qlearning.setModel(copy.deepcopy(deepQModel['model']), deepQModel['trainable_layers'])\n",
        "\n",
        "        series = Series(environnement, agent, epochs, train_list, steps)\n",
        "        self.avgRewards = np.array(series.allRewards[:])\n",
        "\n",
        "        for a in range(num_avg):\n",
        "            # We keep the exact same environnement, but reinitialize the Q-table (testing if we were just lucky in the learning process)\n",
        "            agent = Agent(environnement, memory, choiceMethod, params)\n",
        "            # DeepQlearning setup --------------------------------------------------------------\n",
        "            if choiceMethod == \"DeepQlearning\" or choiceMethod == \"DeepQlearningFaster\":\n",
        "                agent.Qlearning.setModel(copy.deepcopy(deepQModel['model']), deepQModel['trainable_layers'])\n",
        "            # ----------------------------------------------------------------------------------\n",
        "            series = Series(environnement, agent, epochs, train_list, steps)\n",
        "            self.avgRewards =  self.avgRewards  +  np.array(series.allRewards[:])\n",
        "            self.choicesLastSerie_total= self.choicesLastSerie_total + series.choicesLastSerie\n",
        "        self.avgRewards = self.avgRewards/num_avg\n",
        "        self.avgLastReward = self.avgRewards[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X64ubO1mtoWw",
        "colab_type": "text"
      },
      "source": [
        "# Testing (with 100 n_items) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlxnWzcYInAL",
        "colab_type": "text"
      },
      "source": [
        "### \"Similar with subset\" user  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FRN0kGKudsU",
        "colab_type": "text"
      },
      "source": [
        "#### Q-Learning (Action Tuples)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSGFGk0YueRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0c311f2-234e-4d2e-a6e9-16739b74611b"
      },
      "source": [
        "print(\">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER MAKES SIMILAR CHOICES <<<<<<<<<<<<<<<<<<\")\n",
        "print(\"In this setting, the number of recommended items is 2. And only 2 items have a cost of 0. But the customer makes similar choices. Will the agent adapt?\")\n",
        "\n",
        "# ------------ Defining several parameters - others will be chosen by grid search --------------\n",
        "N_items = 100\n",
        "N_recommended = 1\n",
        "memory = 1\n",
        "choiceMethod =  'QlearningActionsTuples'\n",
        "rewardType = 'Trust'\n",
        "behaviour = 'similarWithSubset'\n",
        "rewardParameters = [1,1]\n",
        "steps = 20\n",
        "epochs = 3\n",
        "train_list = [True for u in range(3) ]+[ False, False ]\n",
        "p = 0.5\n",
        "\n",
        "#------------- Defining the environnement  -----------\n",
        "environnement = Environnement(N_items, N_recommended, behaviour,  rewardType , rewardParameters, proba_p=p )\n",
        "environnement.items.display(True)\n",
        "\n",
        "\n",
        "# >>> Grid search over the parameters to get the best parameters\n",
        "gridSearch = GridSearch()\n",
        "num_avg = 3\n",
        "_ , params = gridSearch(num_avg, environnement, memory, choiceMethod, epochs, train_list, steps=steps, more_params = None)\n",
        "\n",
        "\n",
        "\n",
        "#------------ launching the episode series : Average the learning processes results   ---------------\n",
        "#(less randomness in the plots), for statistical study, than the Series class\n",
        "num_avg = 3\n",
        "epochs = 10\n",
        "avgSeries = AverageSeries(num_avg, environnement, memory, choiceMethod, params, epochs, train_list, steps)\n",
        "Rewards = avgSeries.avgRewards\n",
        "\n",
        "plt.figure()\n",
        "plt.plot([str(i)+\"_\"+str(train_list[i]) for i in range(len(train_list))],Rewards, 'r-')\n",
        "plt.ylabel(\"Average reward per serie\")\n",
        "plt.xlabel(\"Serie id and type: true for training, false for testing  \")\n",
        "plt.title(\"Average results of \"+str(num_avg)+\" parallel training/testing sessions\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 10297.07it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER MAKES SIMILAR CHOICES <<<<<<<<<<<<<<<<<<\n",
            "In this setting, the number of recommended items is 2. And only 2 items have a cost of 0. But the customer makes similar choices. Will the agent adapt?\n",
            "---------------- Items ----------------\n",
            "Number of items: 100\n",
            "*** Items list: ***\n",
            "Item 0 -> name:ltp, cost: 1\n",
            "Item 1 -> name:ZOzKyf, cost: 0\n",
            "Item 2 -> name:apBUd6oY, cost: 1\n",
            "Item 3 -> name:vMVsPy, cost: 1\n",
            "Item 4 -> name:YjuVihCxp, cost: 1\n",
            "Item 5 -> name:RAJ, cost: 1\n",
            "Item 6 -> name:fRcnfi, cost: 1\n",
            "Item 7 -> name:PmZPe, cost: 1\n",
            "Item 8 -> name:aMKQx, cost: 1\n",
            "Item 9 -> name:FsM66, cost: 1\n",
            "Item 10 -> name:4FasP, cost: 1\n",
            "Item 11 -> name:rJXxoKvG, cost: 1\n",
            "Item 12 -> name:itQ, cost: 1\n",
            "Item 13 -> name:L7KrFEiX, cost: 1\n",
            "Item 14 -> name:A45X, cost: 1\n",
            "Item 15 -> name:vYw, cost: 1\n",
            "Item 16 -> name:XOfI, cost: 1\n",
            "Item 17 -> name:ViROHF2, cost: 1\n",
            "Item 18 -> name:wkfAO, cost: 1\n",
            "Item 19 -> name:V4GGtuHf, cost: 1\n",
            "Item 20 -> name:Zu1Sh4n, cost: 1\n",
            "Item 21 -> name:5ywcBh, cost: 1\n",
            "Item 22 -> name:o6K5Xyumo, cost: 1\n",
            "Item 23 -> name:rxMPexL, cost: 1\n",
            "Item 24 -> name:tWcnpNW6, cost: 1\n",
            "Item 25 -> name:uhdarRXs, cost: 1\n",
            "Item 26 -> name:IhRw1GV, cost: 1\n",
            "Item 27 -> name:xvzCsQBB, cost: 1\n",
            "Item 28 -> name:ChJjCMfi, cost: 0\n",
            "Item 29 -> name:K1P, cost: 1\n",
            "Item 30 -> name:1n6FGs, cost: 1\n",
            "Item 31 -> name:MBYr, cost: 1\n",
            "Item 32 -> name:O73, cost: 1\n",
            "Item 33 -> name:GIW, cost: 1\n",
            "Item 34 -> name:DawA, cost: 1\n",
            "Item 35 -> name:2pIJJ, cost: 1\n",
            "Item 36 -> name:rcngF, cost: 1\n",
            "Item 37 -> name:iLKo, cost: 1\n",
            "Item 38 -> name:WX2GobXM, cost: 1\n",
            "Item 39 -> name:h7uPlGdx, cost: 1\n",
            "Item 40 -> name:bDP1, cost: 1\n",
            "Item 41 -> name:VoqiiLk, cost: 0\n",
            "Item 42 -> name:kDo8CYP, cost: 1\n",
            "Item 43 -> name:Q5Va, cost: 1\n",
            "Item 44 -> name:SaEixFZ, cost: 0\n",
            "Item 45 -> name:Qmb7G, cost: 1\n",
            "Item 46 -> name:oiKq, cost: 1\n",
            "Item 47 -> name:c2K1Vd, cost: 1\n",
            "Item 48 -> name:NNMj, cost: 1\n",
            "Item 49 -> name:H7fFR, cost: 1\n",
            "Item 50 -> name:Savc7Giwu, cost: 1\n",
            "Item 51 -> name:OwdSpr2, cost: 1\n",
            "Item 52 -> name:k2c3V, cost: 1\n",
            "Item 53 -> name:6dbirUcCg, cost: 1\n",
            "Item 54 -> name:tBsDQSlT, cost: 1\n",
            "Item 55 -> name:zEPH3, cost: 1\n",
            "Item 56 -> name:xwHF7ox, cost: 1\n",
            "Item 57 -> name:VKU, cost: 1\n",
            "Item 58 -> name:jMmBtpL5O, cost: 1\n",
            "Item 59 -> name:nAsi, cost: 1\n",
            "Item 60 -> name:qUWLWr5aA, cost: 1\n",
            "Item 61 -> name:5FRtK0, cost: 1\n",
            "Item 62 -> name:uhp9stQ, cost: 1\n",
            "Item 63 -> name:2TE, cost: 0\n",
            "Item 64 -> name:ghwzlB, cost: 1\n",
            "Item 65 -> name:Mu30Yr7L, cost: 1\n",
            "Item 66 -> name:wgso, cost: 1\n",
            "Item 67 -> name:56qt, cost: 1\n",
            "Item 68 -> name:RdnrJv4J, cost: 1\n",
            "Item 69 -> name:DGmEr51D, cost: 1\n",
            "Item 70 -> name:SLEhH, cost: 1\n",
            "Item 71 -> name:dKGgB, cost: 1\n",
            "Item 72 -> name:NoEBjUZ, cost: 1\n",
            "Item 73 -> name:mqS2A, cost: 1\n",
            "Item 74 -> name:9qUTqdIu, cost: 1\n",
            "Item 75 -> name:aT19, cost: 1\n",
            "Item 76 -> name:eeehA8, cost: 1\n",
            "Item 77 -> name:1ebE6, cost: 0\n",
            "Item 78 -> name:Ls8YVCXhG, cost: 1\n",
            "Item 79 -> name:y9xq3, cost: 1\n",
            "Item 80 -> name:IgmHB, cost: 1\n",
            "Item 81 -> name:Kz2, cost: 0\n",
            "Item 82 -> name:wMI, cost: 1\n",
            "Item 83 -> name:SxU1Pa, cost: 1\n",
            "Item 84 -> name:BcnCfOT, cost: 1\n",
            "Item 85 -> name:e2lERIYA, cost: 1\n",
            "Item 86 -> name:9Fjh, cost: 1\n",
            "Item 87 -> name:Hfbdli, cost: 1\n",
            "Item 88 -> name:hHmwnzV69, cost: 1\n",
            "Item 89 -> name:2MYt, cost: 1\n",
            "Item 90 -> name:1JDzPE, cost: 1\n",
            "Item 91 -> name:DqEd, cost: 1\n",
            "Item 92 -> name:wvc, cost: 1\n",
            "Item 93 -> name:OEX7e, cost: 1\n",
            "Item 94 -> name:dkJNto1vZ, cost: 1\n",
            "Item 95 -> name:kWAZilm9u, cost: 1\n",
            "Item 96 -> name:UW185FKF, cost: 1\n",
            "Item 97 -> name:fyxl, cost: 1\n",
            "Item 98 -> name:JMM1BrPEi, cost: 1\n",
            "Item 99 -> name:SDEGs, cost: 1\n",
            "***************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:10<00:00,  2.75s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "******** Grid Search results : *******\n",
            "best_reward: 0.44444444444444464\n",
            "best parameters \n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.4, 'learning_rate': 0.01, 'gamma': 0.7}\n",
            "**************************************\n",
            " \n",
            " \n",
            " Execution time of grid Search: 10.993767499923706\n",
            "------------------> Average of series begins:  <------------------\n",
            "3 independent training/testing processes\n",
            "environnement name: envi_01\n",
            "Memory size: 1\n",
            "Number of items to recommend: 1\n",
            "--- We will test the following hyperparameters ---\n",
            "choice method: QlearningActionsTuples\n",
            "epochs: 10\n",
            "Reward hyper parameters: [1, 1]\n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.4, 'learning_rate': 0.01, 'gamma': 0.7}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  6.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " Execution time: 0.45714831352233887\n",
            "Qtable of the last series ------------------------------>\n",
            "[[-inf   0.   0. ...   0.   0.   0.]\n",
            " [  0. -inf   0. ...   0.   0.   0.]\n",
            " [  0.   0. -inf ...   0.   0.   0.]\n",
            " ...\n",
            " [  0.   0.   0. ... -inf   0.   0.]\n",
            " [  0.   0.   0. ...   0. -inf   0.]\n",
            " [  0.   0.   0. ...   0.   0. -inf]]\n",
            "---------------------------------------------------->\n",
            " \n",
            "After the learning process : how often  is an item recommended? (total of all series) \n",
            "[ 0.  3.  0.  1.  0.  2.  0.  1. 23.  0.  0.  0.  0.  1.  6.  0.  0.  0.\n",
            "  0. 32.  0.  1.  0.  0.  0.  1.  1.  2.  2.  1.  0.  1. 22.  0.  1.  0.\n",
            "  0. 21.  1.  4.  0. 31.  1.  0. 21.  0.  0.  1.  0.  0.  1. 21.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0. 55.  2.  0.  0.  0.  0.  0.  3.  3.\n",
            " 30.  2.  2.  0.  6. 21.  0.  0.  4. 27.  1.  0.  4.  2.  0.  3.  1.  0.\n",
            "  2.  0.  0. 27.  0.  0.  1.  1.  0.  0.]\n",
            "After the learning process : how often  is an Action tuple recommended? (total of all series) \n",
            "Action list:\n",
            "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\n",
            "Action ids list:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Number of time selected (per action id):\n",
            "[ 0.  3.  0.  1.  0.  2.  0.  1. 23.  0.  0.  0.  0.  1.  6.  0.  0.  0.\n",
            "  0. 32.  0.  1.  0.  0.  0.  1.  1.  2.  2.  1.  0.  1. 22.  0.  1.  0.\n",
            "  0. 21.  1.  4.  0. 31.  1.  0. 21.  0.  0.  1.  0.  0.  1. 21.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0. 55.  2.  0.  0.  0.  0.  0.  3.  3.\n",
            " 30.  2.  2.  0.  6. 21.  0.  0.  4. 27.  1.  0.  4.  2.  0.  3.  1.  0.\n",
            "  2.  0.  0. 27.  0.  0.  1.  1.  0.  0.]\n",
            "Most recommended action: [63]\n",
            "------------------> Series ends <------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAOpomKeuoc-",
        "colab_type": "text"
      },
      "source": [
        "#### Q-Learning (Linear) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LAfWg8Zuo-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebbe38ea-d6db-4bf1-90f5-28d5d7cb195a"
      },
      "source": [
        "print(\">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER MAKES SIMILAR CHOICES <<<<<<<<<<<<<<<<<<\")\n",
        "print(\"In this setting, the number of recommended items is 2. And only 2 items have a cost of 0. But the customer makes similar choices. Will the agent adapt?\")\n",
        "\n",
        "# ------------ Defining several parameters - others will be chosen by grid search --------------\n",
        "N_items = 100\n",
        "N_recommended = 1\n",
        "memory = 1\n",
        "choiceMethod =   'LinearQlearning'\n",
        "rewardType = 'Trust'\n",
        "behaviour = 'similarWithSubset'\n",
        "rewardParameters = [1,1]\n",
        "steps = 10\n",
        "epochs = 3\n",
        "train_list = [True for u in range(3) ]+[ False, False ]\n",
        "p = 0.7\n",
        "\n",
        "#------------- Defining the environnement  -----------\n",
        "environnement = Environnement(N_items, N_recommended, behaviour,  rewardType , rewardParameters, proba_p=p )\n",
        "environnement.items.display(True)\n",
        "\n",
        "#------------- Defining the environnement  -----------\n",
        "# >>> Grid search over the parameters to get the best parameters\n",
        "gridSearch = GridSearch()\n",
        "num_avg = 3\n",
        "_ , params = gridSearch(num_avg, environnement, memory, choiceMethod, epochs, train_list, steps=steps)\n",
        "#params = {'gamma': 0.1, 'hidden_size': 10, 'epsilon': 0.2, 'learning_rate': 0.01, 'QLchoiceMethod': 'eGreedy'}\n",
        "\n",
        "\n",
        "#------------ launching the episode series : Average the learning processes results   ---------------\n",
        "#(less randomness in the plots), for statistical study, than the Series class\n",
        "num_avg = 3\n",
        "epochs = 10\n",
        "avgSeries = AverageSeries(num_avg, environnement, memory, choiceMethod, params, epochs, train_list, steps)\n",
        "Rewards = avgSeries.avgRewards\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot([str(i)+\"_\"+str(train_list[i]) for i in range(len(train_list))],Rewards, 'r-')\n",
        "plt.ylabel(\"Average reward per serie\")\n",
        "plt.xlabel(\"Serie id and type: true for training, false for testing  \")\n",
        "plt.title(\"Average results of \"+str(num_avg)+\" parallel training/testing sessions\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 11938.36it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER MAKES SIMILAR CHOICES <<<<<<<<<<<<<<<<<<\n",
            "In this setting, the number of recommended items is 2. And only 2 items have a cost of 0. But the customer makes similar choices. Will the agent adapt?\n",
            "---------------- Items ----------------\n",
            "Number of items: 100\n",
            "*** Items list: ***\n",
            "Item 0 -> name:Bh0, cost: 0\n",
            "Item 1 -> name:LhhLoh, cost: 1\n",
            "Item 2 -> name:MXrCAJ, cost: 1\n",
            "Item 3 -> name:J4d, cost: 1\n",
            "Item 4 -> name:AII, cost: 1\n",
            "Item 5 -> name:UewDDnj1, cost: 1\n",
            "Item 6 -> name:loIv, cost: 1\n",
            "Item 7 -> name:12oU, cost: 1\n",
            "Item 8 -> name:Ufhic, cost: 1\n",
            "Item 9 -> name:naT5u, cost: 1\n",
            "Item 10 -> name:CnREA, cost: 1\n",
            "Item 11 -> name:2h2aW, cost: 0\n",
            "Item 12 -> name:nAXrM, cost: 1\n",
            "Item 13 -> name:CD4Xy6, cost: 1\n",
            "Item 14 -> name:XAVQ, cost: 1\n",
            "Item 15 -> name:Qss0q, cost: 1\n",
            "Item 16 -> name:rATip, cost: 1\n",
            "Item 17 -> name:nWCkjOaMx, cost: 1\n",
            "Item 18 -> name:gn5lRsS0, cost: 1\n",
            "Item 19 -> name:wQe9k, cost: 1\n",
            "Item 20 -> name:pVcoaNf, cost: 1\n",
            "Item 21 -> name:6prLzox, cost: 1\n",
            "Item 22 -> name:P6nV, cost: 1\n",
            "Item 23 -> name:RyW58s, cost: 1\n",
            "Item 24 -> name:Msu, cost: 1\n",
            "Item 25 -> name:WuOTlstv, cost: 1\n",
            "Item 26 -> name:K0ob, cost: 1\n",
            "Item 27 -> name:WsQ1, cost: 1\n",
            "Item 28 -> name:YvEJf7, cost: 1\n",
            "Item 29 -> name:PNRDhV, cost: 1\n",
            "Item 30 -> name:uX3sWzv, cost: 1\n",
            "Item 31 -> name:oUMH3x, cost: 1\n",
            "Item 32 -> name:RBK1dQH, cost: 1\n",
            "Item 33 -> name:rvDuQ, cost: 1\n",
            "Item 34 -> name:GoOt4x, cost: 1\n",
            "Item 35 -> name:ASSA, cost: 1\n",
            "Item 36 -> name:7d0Moa6, cost: 1\n",
            "Item 37 -> name:jfqKe0J, cost: 1\n",
            "Item 38 -> name:g3V, cost: 1\n",
            "Item 39 -> name:w2rgYE, cost: 1\n",
            "Item 40 -> name:LjteCVaL0, cost: 0\n",
            "Item 41 -> name:Y2apGC, cost: 1\n",
            "Item 42 -> name:JwqjIW, cost: 1\n",
            "Item 43 -> name:Vwbty, cost: 1\n",
            "Item 44 -> name:Cz0P, cost: 1\n",
            "Item 45 -> name:aklhJPKGc, cost: 1\n",
            "Item 46 -> name:mCuQa1Z, cost: 1\n",
            "Item 47 -> name:gyV9bJ, cost: 1\n",
            "Item 48 -> name:A4zD, cost: 1\n",
            "Item 49 -> name:dwK, cost: 1\n",
            "Item 50 -> name:JyC3X, cost: 1\n",
            "Item 51 -> name:HwvBZJ, cost: 1\n",
            "Item 52 -> name:hnTf, cost: 1\n",
            "Item 53 -> name:abXbMMRW7, cost: 1\n",
            "Item 54 -> name:DuZ, cost: 1\n",
            "Item 55 -> name:h9mD, cost: 1\n",
            "Item 56 -> name:Zlzx, cost: 1\n",
            "Item 57 -> name:nojMPt, cost: 0\n",
            "Item 58 -> name:6El3P3XZ, cost: 1\n",
            "Item 59 -> name:Kllh, cost: 1\n",
            "Item 60 -> name:ezbliL3, cost: 1\n",
            "Item 61 -> name:Kb7, cost: 1\n",
            "Item 62 -> name:HFUt, cost: 1\n",
            "Item 63 -> name:efJnXB, cost: 1\n",
            "Item 64 -> name:JFI1y, cost: 1\n",
            "Item 65 -> name:BMNJtdFZ8, cost: 1\n",
            "Item 66 -> name:UKMEiEd, cost: 1\n",
            "Item 67 -> name:nSMUP, cost: 1\n",
            "Item 68 -> name:xJ2E, cost: 1\n",
            "Item 69 -> name:jImXNjS3w, cost: 1\n",
            "Item 70 -> name:CDKB0MVGm, cost: 1\n",
            "Item 71 -> name:ov9iFMj2, cost: 1\n",
            "Item 72 -> name:vNm3P2SE, cost: 1\n",
            "Item 73 -> name:Ze2Kb, cost: 1\n",
            "Item 74 -> name:YJa, cost: 1\n",
            "Item 75 -> name:0kUJj73b, cost: 1\n",
            "Item 76 -> name:QERlV4y, cost: 1\n",
            "Item 77 -> name:nsD5xem, cost: 1\n",
            "Item 78 -> name:pMbK, cost: 1\n",
            "Item 79 -> name:GMHy6O, cost: 1\n",
            "Item 80 -> name:IAW3, cost: 1\n",
            "Item 81 -> name:cGRFRj5r, cost: 1\n",
            "Item 82 -> name:8Aw, cost: 1\n",
            "Item 83 -> name:F7KfC, cost: 1\n",
            "Item 84 -> name:Ajw9h4, cost: 1\n",
            "Item 85 -> name:286My, cost: 1\n",
            "Item 86 -> name:k6TfT, cost: 1\n",
            "Item 87 -> name:iT6QXkD, cost: 1\n",
            "Item 88 -> name:jg8, cost: 1\n",
            "Item 89 -> name:urN, cost: 1\n",
            "Item 90 -> name:gXJ, cost: 1\n",
            "Item 91 -> name:KsYZLAS85, cost: 1\n",
            "Item 92 -> name:nwm74, cost: 1\n",
            "Item 93 -> name:zu3Vo4, cost: 1\n",
            "Item 94 -> name:4JadEV, cost: 1\n",
            "Item 95 -> name:TnVzup4C, cost: 1\n",
            "Item 96 -> name:jhp, cost: 1\n",
            "Item 97 -> name:fqO, cost: 1\n",
            "Item 98 -> name:4r4RlO, cost: 1\n",
            "Item 99 -> name:LO1xs, cost: 1\n",
            "***************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:26<00:00,  6.65s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "******** Grid Search results : *******\n",
            "best_reward: 12.222222222222223\n",
            "best parameters \n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.1, 'learning_rate': 1, 'gamma': 0.5}\n",
            "**************************************\n",
            " \n",
            " \n",
            " Execution time of grid Search: 26.596111059188843\n",
            "------------------> Average of series begins:  <------------------\n",
            "3 independent training/testing processes\n",
            "environnement name: envi_01\n",
            "Memory size: 1\n",
            "Number of items to recommend: 1\n",
            "--- We will test the following hyperparameters ---\n",
            "choice method: LinearQlearning\n",
            "epochs: 10\n",
            "Reward hyper parameters: [1, 1]\n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.1, 'learning_rate': 1, 'gamma': 0.5}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " Execution time: 1.144394874572754\n",
            "Final weights: \n",
            "[[-0.48180419]\n",
            " [-0.35500837]\n",
            " [ 2.36797438]]\n",
            "Action list:\n",
            "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\n",
            "Action ids list:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Number of time selected (per action id):\n",
            "[72.  0.  0.  5.  5.  0.  0.  0.  0.  0.  0.  7.  0.  0.  0.  0.  4.  0.\n",
            "  5.  0.  5.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0. 69.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
            "  0.  0.  0.  8.  5.  0.  5.  0.  0.  5.  0.  0.  0.  1.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "Most recommended action: [0]\n",
            "------------------> Series ends <------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFk4POmKutZO",
        "colab_type": "text"
      },
      "source": [
        "#### Q-Learning (Deep) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcnPiNJ9uuTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b87526f-811c-4f4c-e93a-2202995faeb9"
      },
      "source": [
        "print(\">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER ALWAYS CHOOSES THE FIRST RECOMMENDATION <<<<<<<<<<<<<<<<<<\")\n",
        "import torch\n",
        "# ------------ Defining several parameters - others will be chosen by grid search --------------\n",
        "N_items = 100\n",
        "N_recommended = 1\n",
        "memory = 1\n",
        "choiceMethod =  'DeepQlearning'\n",
        "rewardType = 'Trust'\n",
        "behaviour = 'similarWithSubset'\n",
        "rewardParameters = [1,1]\n",
        "steps = 10\n",
        "epochs = 3\n",
        "train_list = [True for u in range(3) ]+[ False, False ]\n",
        "\n",
        "#------------- Defining the environnement  -----------\n",
        "environnement = Environnement(N_items, N_recommended, behaviour,  rewardType , rewardParameters )\n",
        "\n",
        "\n",
        "environnement.items.display(True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(memory+2*N_recommended, 10),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(10, 1)\n",
        ")\n",
        "\n",
        "trainable_layers = [0,2]\n",
        "\n",
        "deepQModel = {'model': model, 'trainable_layers': trainable_layers}\n",
        "\n",
        "# >>> Grid search over the parameters to get the best parameters\n",
        "gridSearch = GridSearch()\n",
        "num_avg = 3\n",
        "_ , params = gridSearch(num_avg, environnement, memory, choiceMethod, epochs, train_list, steps=steps, more_params = None, deepQModel=deepQModel)\n",
        "\n",
        "print(\"Testing the Grid Search parameters: \")\n",
        "\n",
        "#------------ launching the episode series : Average the learning processes results   ---------------\n",
        "#(less randomness in the plots), for statistical study, than the Series class\n",
        "num_avg = 3\n",
        "epochs = 10\n",
        "avgSeries = AverageSeries(num_avg, environnement, memory, choiceMethod, params, epochs, train_list, steps, deepQModel)\n",
        "Rewards = avgSeries.avgRewards\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot([str(i)+\"_\"+str(train_list[i]) for i in range(len(train_list))],Rewards, 'r-')\n",
        "plt.ylabel(\"Average reward per serie\")\n",
        "plt.xlabel(\"Serie id and type: true for training, false for testing  \")\n",
        "plt.title(\"Average results of \"+str(num_avg)+\" parallel training/testing sessions\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 11718.22it/s]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER ALWAYS CHOOSES THE FIRST RECOMMENDATION <<<<<<<<<<<<<<<<<<\n",
            "---------------- Items ----------------\n",
            "Number of items: 100\n",
            "*** Items list: ***\n",
            "Item 0 -> name:NTYh, cost: 0\n",
            "Item 1 -> name:jhRkyATw, cost: 1\n",
            "Item 2 -> name:ZlZby1vmi, cost: 1\n",
            "Item 3 -> name:Oyqx7, cost: 1\n",
            "Item 4 -> name:Bw5sA2o, cost: 1\n",
            "Item 5 -> name:PaaDzM, cost: 1\n",
            "Item 6 -> name:kVrpG6O4, cost: 1\n",
            "Item 7 -> name:XnZ0l, cost: 1\n",
            "Item 8 -> name:IebF, cost: 1\n",
            "Item 9 -> name:l3RL28hj, cost: 1\n",
            "Item 10 -> name:yWo4Qu, cost: 1\n",
            "Item 11 -> name:x9po7U9, cost: 0\n",
            "Item 12 -> name:uvXRAV, cost: 1\n",
            "Item 13 -> name:pk1Usr5, cost: 1\n",
            "Item 14 -> name:vTbKCqY, cost: 1\n",
            "Item 15 -> name:3Gg, cost: 1\n",
            "Item 16 -> name:kGR1, cost: 1\n",
            "Item 17 -> name:hutDH6z, cost: 1\n",
            "Item 18 -> name:Ty1EF, cost: 1\n",
            "Item 19 -> name:eh3z, cost: 1\n",
            "Item 20 -> name:dkgumPis, cost: 1\n",
            "Item 21 -> name:MOBT, cost: 1\n",
            "Item 22 -> name:pJuTUig, cost: 1\n",
            "Item 23 -> name:4Pf, cost: 1\n",
            "Item 24 -> name:QNt5R4P, cost: 1\n",
            "Item 25 -> name:DN1, cost: 1\n",
            "Item 26 -> name:NMANn, cost: 1\n",
            "Item 27 -> name:dYhXdoci, cost: 1\n",
            "Item 28 -> name:Vcn, cost: 1\n",
            "Item 29 -> name:9uijWi6u, cost: 0\n",
            "Item 30 -> name:DQxzlb2dL, cost: 1\n",
            "Item 31 -> name:kqBZo, cost: 1\n",
            "Item 32 -> name:GgsaGn, cost: 1\n",
            "Item 33 -> name:Ahrl7VEf, cost: 1\n",
            "Item 34 -> name:ZEyDytT4l, cost: 1\n",
            "Item 35 -> name:kC7vjWm, cost: 1\n",
            "Item 36 -> name:rDfhgPZX, cost: 0\n",
            "Item 37 -> name:X8EX50, cost: 1\n",
            "Item 38 -> name:0Ro, cost: 1\n",
            "Item 39 -> name:PtU1uYR, cost: 1\n",
            "Item 40 -> name:sBxo9y, cost: 1\n",
            "Item 41 -> name:5pZoKsD5j, cost: 1\n",
            "Item 42 -> name:A6bpMS, cost: 0\n",
            "Item 43 -> name:NMVJT8Lt, cost: 1\n",
            "Item 44 -> name:eCqfXJWc, cost: 1\n",
            "Item 45 -> name:Ccr, cost: 1\n",
            "Item 46 -> name:OuLl, cost: 1\n",
            "Item 47 -> name:2JTpQG, cost: 1\n",
            "Item 48 -> name:uA1Ds, cost: 1\n",
            "Item 49 -> name:Z9zczB8J, cost: 1\n",
            "Item 50 -> name:LI6nQ, cost: 1\n",
            "Item 51 -> name:BJ9xg5I, cost: 1\n",
            "Item 52 -> name:G0PgWz, cost: 1\n",
            "Item 53 -> name:zMmT, cost: 1\n",
            "Item 54 -> name:FRY, cost: 1\n",
            "Item 55 -> name:Efh8MPLMa, cost: 1\n",
            "Item 56 -> name:oP6k1Q, cost: 1\n",
            "Item 57 -> name:u2VU7Wwym, cost: 1\n",
            "Item 58 -> name:VyN4DV, cost: 1\n",
            "Item 59 -> name:sDSsRr9U, cost: 1\n",
            "Item 60 -> name:4hNfO1, cost: 1\n",
            "Item 61 -> name:X8GFO1, cost: 1\n",
            "Item 62 -> name:xR8Pka4, cost: 0\n",
            "Item 63 -> name:5NxHYFu, cost: 1\n",
            "Item 64 -> name:CORrd, cost: 1\n",
            "Item 65 -> name:shv, cost: 1\n",
            "Item 66 -> name:U6oKgRS, cost: 1\n",
            "Item 67 -> name:VWBqeuvAx, cost: 1\n",
            "Item 68 -> name:qnR8, cost: 1\n",
            "Item 69 -> name:u7WnLQ, cost: 1\n",
            "Item 70 -> name:F8qKZ1a, cost: 1\n",
            "Item 71 -> name:brnxAH8, cost: 1\n",
            "Item 72 -> name:lPYPh, cost: 1\n",
            "Item 73 -> name:cA5Zq9lk, cost: 1\n",
            "Item 74 -> name:3gR9g, cost: 1\n",
            "Item 75 -> name:E7kZ, cost: 1\n",
            "Item 76 -> name:jRmqBDRJ, cost: 1\n",
            "Item 77 -> name:5Q0F, cost: 1\n",
            "Item 78 -> name:uSzgCyVY, cost: 1\n",
            "Item 79 -> name:LKJw5p, cost: 1\n",
            "Item 80 -> name:OduPvcvHY, cost: 1\n",
            "Item 81 -> name:l0ES, cost: 1\n",
            "Item 82 -> name:qoI9etv, cost: 1\n",
            "Item 83 -> name:7reYXko, cost: 1\n",
            "Item 84 -> name:0Lf, cost: 1\n",
            "Item 85 -> name:PPlYbNw, cost: 1\n",
            "Item 86 -> name:N3TLXSVS, cost: 1\n",
            "Item 87 -> name:j5YNdA3, cost: 1\n",
            "Item 88 -> name:eum7uiX, cost: 1\n",
            "Item 89 -> name:6sSeG, cost: 1\n",
            "Item 90 -> name:Q6HB, cost: 1\n",
            "Item 91 -> name:i8In2O, cost: 1\n",
            "Item 92 -> name:c814si, cost: 1\n",
            "Item 93 -> name:EC7, cost: 1\n",
            "Item 94 -> name:S81, cost: 1\n",
            "Item 95 -> name:BzzY, cost: 1\n",
            "Item 96 -> name:fDTQZqsI, cost: 1\n",
            "Item 97 -> name:XZe1EvnZ, cost: 1\n",
            "Item 98 -> name:EfYJvZFyg, cost: 1\n",
            "Item 99 -> name:7axQ, cost: 1\n",
            "***************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [02:44<00:00, 54.68s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "******** Grid Search results : *******\n",
            "best_reward: 10.666666666666666\n",
            "best parameters \n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.1, 'learning_rate': 0.001, 'gamma': 0.9}\n",
            "**************************************\n",
            " \n",
            " \n",
            " Execution time of grid Search: 164.0341398715973\n",
            "Testing the Grid Search parameters: \n",
            "------------------> Average of series begins:  <------------------\n",
            "3 independent training/testing processes\n",
            "environnement name: envi_01\n",
            "Memory size: 1\n",
            "Number of items to recommend: 1\n",
            "--- We will test the following hyperparameters ---\n",
            "choice method: DeepQlearning\n",
            "epochs: 10\n",
            "Reward hyper parameters: [1, 1]\n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.1, 'learning_rate': 0.001, 'gamma': 0.9}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:15<00:00,  7.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " Execution time: 22.80694317817688\n",
            "--------------------------> Q learning ( neural network approximation) method :\n",
            " memory: 1\n",
            " number of items to recommend at each step : 1\n",
            " learning rate: 0.001\n",
            " gamma: 0.9\n",
            "trainable layers ids: [0, 2]\n",
            "Model:\n",
            "Sequential(\n",
            "  (0): Linear(in_features=3, out_features=10, bias=True)\n",
            "  (1): SELU()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            " <---- Weight and bias of Layer 0 ---->\n",
            "Weight -->\n",
            "tensor([[-0.2413,  0.2252,  0.0984],\n",
            "        [ 0.3353,  0.1450,  0.1539],\n",
            "        [-0.1056, -0.4696, -0.3062],\n",
            "        [ 0.5668, -0.2561,  0.5004],\n",
            "        [ 0.5037,  0.1779, -0.1713],\n",
            "        [ 0.0163, -0.4027,  0.3910],\n",
            "        [-0.3231, -0.1181,  0.4725],\n",
            "        [-0.4251, -0.4705, -0.5555],\n",
            "        [ 0.4235, -0.4544, -0.3605],\n",
            "        [-0.3410,  0.2591, -0.2932]])\n",
            "Bias -->\n",
            "tensor([-0.0537, -0.5448,  0.0845, -0.4466, -0.1894, -0.2364,  0.4316, -0.3399,\n",
            "        -0.4136,  0.2475])\n",
            "\n",
            " <---- Weight and bias of Layer 2 ---->\n",
            "Weight -->\n",
            "tensor([[ 0.0459, -0.0538, -0.0194,  0.1477, -0.0383, -0.1108,  0.1120, -0.1370,\n",
            "          0.1609, -0.1916]])\n",
            "Bias -->\n",
            "tensor([0.1603])\n",
            "----------------------------------------------------\n",
            "Action list:\n",
            "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\n",
            "Action ids list:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Number of time selected (per action id):\n",
            "[30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 22.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 54.  0.  0.  0.  0.  0.  0.\n",
            " 48.  0.  0.  0.  0.  0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0. 30.  0.  0.  0.  0.  0.  0.]\n",
            "Most recommended action: [29]\n",
            "------------------> Series ends <------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq7K1cb6p6KO",
        "colab_type": "text"
      },
      "source": [
        "### \"Similar\" user  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_6wpH2We7QN",
        "colab_type": "text"
      },
      "source": [
        "#### Q-Learning (Action Tuples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHrdHBGGuDgR",
        "colab_type": "text"
      },
      "source": [
        "Similar setting than before, with 'similar' user behaviour. \n",
        "However:\n",
        "- the cost of item \"2\" is 0 all the other ones have a cost of 1\n",
        "- the item \"3\" is very similar to all other items (similarity = 0.8), whereas all of the other similarities between items is set to 0.1.\n",
        "\n",
        "We can see in the results that the item \"3\" and \"2\" are the most recommended items. Even though \"3\" is of cost 1  \"3\" is more often recommended than the rest, because the reward is set to \"trust\", and \"3\" has high similarity scores (and therefore is a \"good quality item\").\n",
        "\"2\" is recommended when \"3\" is the currently consumed content, as it is the lowest cost item.\n",
        "The aim of this cell is to show that the agent adapts to both cost and quality.\n",
        "\n",
        "Note that in this case, the environnement does not allow us to get a best possible reward equal to the number of steps. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgR97FnFe82v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cdf4917f-5bfe-4bb2-f8cc-17649953441d"
      },
      "source": [
        "print(\">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER MAKES SIMILAR CHOICES <<<<<<<<<<<<<<<<<<\")\n",
        "print(\"In this setting, the number of recommended items is 2. And only 2 items have a cost of 0. But the customer makes similar choices. Will the agent adapt?\")\n",
        "\n",
        "# ------------ Defining several parameters - others will be chosen by grid search --------------\n",
        "N_items = 100\n",
        "N_recommended = 1\n",
        "memory = 1\n",
        "choiceMethod =  'QlearningActionsTuples'\n",
        "rewardType = 'Trust'\n",
        "behaviour = 'similar'\n",
        "rewardParameters = [1,1]\n",
        "steps = 20\n",
        "epochs = 3\n",
        "train_list = [True for u in range(3) ]+[ False, False ]\n",
        "p = 0.5\n",
        "\n",
        "#------------- Defining the environnement  -----------\n",
        "environnement = Environnement(N_items, N_recommended, behaviour,  rewardType , rewardParameters, proba_p=p )\n",
        "environnement.items.display(True)\n",
        "\n",
        "\n",
        "# >>> Grid search over the parameters to get the best parameters\n",
        "gridSearch = GridSearch()\n",
        "num_avg = 3\n",
        "_ , params = gridSearch(num_avg, environnement, memory, choiceMethod, epochs, train_list, steps=steps, more_params = None)\n",
        "\n",
        "\n",
        "\n",
        "#------------ launching the episode series : Average the learning processes results   ---------------\n",
        "#(less randomness in the plots), for statistical study, than the Series class\n",
        "num_avg = 3\n",
        "epochs = 10\n",
        "avgSeries = AverageSeries(num_avg, environnement, memory, choiceMethod, params, epochs, train_list, steps)\n",
        "Rewards = avgSeries.avgRewards\n",
        "\n",
        "plt.figure()\n",
        "plt.plot([str(i)+\"_\"+str(train_list[i]) for i in range(len(train_list))],Rewards, 'r-')\n",
        "plt.ylabel(\"Average reward per serie\")\n",
        "plt.xlabel(\"Serie id and type: true for training, false for testing  \")\n",
        "plt.title(\"Average results of \"+str(num_avg)+\" parallel training/testing sessions\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 15627.65it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER MAKES SIMILAR CHOICES <<<<<<<<<<<<<<<<<<\n",
            "In this setting, the number of recommended items is 2. And only 2 items have a cost of 0. But the customer makes similar choices. Will the agent adapt?\n",
            "---------------- Items ----------------\n",
            "Number of items: 100\n",
            "*** Items list: ***\n",
            "Item 0 -> name:ttUx, cost: 1\n",
            "Item 1 -> name:x3ysKoC, cost: 1\n",
            "Item 2 -> name:71QV, cost: 1\n",
            "Item 3 -> name:G3iAZvAD, cost: 0\n",
            "Item 4 -> name:DrD, cost: 1\n",
            "Item 5 -> name:yCTKpX, cost: 1\n",
            "Item 6 -> name:P4qOwqVV, cost: 1\n",
            "Item 7 -> name:aw6, cost: 1\n",
            "Item 8 -> name:6IXA7wI8, cost: 1\n",
            "Item 9 -> name:oodBqN, cost: 1\n",
            "Item 10 -> name:zR5giatdx, cost: 1\n",
            "Item 11 -> name:XgmN5, cost: 1\n",
            "Item 12 -> name:UDuZr, cost: 1\n",
            "Item 13 -> name:Csim, cost: 1\n",
            "Item 14 -> name:SV0pd, cost: 1\n",
            "Item 15 -> name:gvdW, cost: 1\n",
            "Item 16 -> name:x1iXG4Xj, cost: 1\n",
            "Item 17 -> name:IO0EA, cost: 1\n",
            "Item 18 -> name:9ejU, cost: 1\n",
            "Item 19 -> name:IcTG, cost: 1\n",
            "Item 20 -> name:D7U, cost: 1\n",
            "Item 21 -> name:2g4, cost: 1\n",
            "Item 22 -> name:uoiRRY, cost: 1\n",
            "Item 23 -> name:oNcaG12, cost: 1\n",
            "Item 24 -> name:ruiM, cost: 1\n",
            "Item 25 -> name:Sloo, cost: 1\n",
            "Item 26 -> name:t7VYpH, cost: 1\n",
            "Item 27 -> name:nxYrSBG, cost: 1\n",
            "Item 28 -> name:ekduiNbfT, cost: 1\n",
            "Item 29 -> name:zqI19, cost: 1\n",
            "Item 30 -> name:JUvG5M5, cost: 1\n",
            "Item 31 -> name:eUf2Yx, cost: 1\n",
            "Item 32 -> name:feTsB7ZP, cost: 1\n",
            "Item 33 -> name:0yKWTRypf, cost: 0\n",
            "Item 34 -> name:0L8yw2w, cost: 1\n",
            "Item 35 -> name:HsJjfBDBb, cost: 1\n",
            "Item 36 -> name:OOeD, cost: 1\n",
            "Item 37 -> name:NQ6Jyx, cost: 1\n",
            "Item 38 -> name:yEWiM3, cost: 1\n",
            "Item 39 -> name:HVIY, cost: 1\n",
            "Item 40 -> name:hD8fh, cost: 1\n",
            "Item 41 -> name:Nl74F1o, cost: 1\n",
            "Item 42 -> name:HlBgFVk1, cost: 1\n",
            "Item 43 -> name:YU7a5GrZR, cost: 1\n",
            "Item 44 -> name:8JEBBeqGW, cost: 1\n",
            "Item 45 -> name:wYKE, cost: 0\n",
            "Item 46 -> name:rJqzgqDmn, cost: 1\n",
            "Item 47 -> name:ZwmE9, cost: 1\n",
            "Item 48 -> name:STGm, cost: 1\n",
            "Item 49 -> name:VrgfIHHU, cost: 1\n",
            "Item 50 -> name:XuGeR5, cost: 0\n",
            "Item 51 -> name:ecjetdSSQ, cost: 1\n",
            "Item 52 -> name:m5jcL1flC, cost: 1\n",
            "Item 53 -> name:3GPUzT, cost: 1\n",
            "Item 54 -> name:Kxe, cost: 1\n",
            "Item 55 -> name:wnT9jPP, cost: 1\n",
            "Item 56 -> name:8yNqN, cost: 1\n",
            "Item 57 -> name:efEx, cost: 1\n",
            "Item 58 -> name:9VVBtGfyo, cost: 1\n",
            "Item 59 -> name:K5dceA, cost: 1\n",
            "Item 60 -> name:j3LmiG6Q, cost: 1\n",
            "Item 61 -> name:3t4B, cost: 1\n",
            "Item 62 -> name:a9b, cost: 1\n",
            "Item 63 -> name:V9lgeJSxR, cost: 1\n",
            "Item 64 -> name:88d5RKg, cost: 1\n",
            "Item 65 -> name:1Mvv8sxb, cost: 1\n",
            "Item 66 -> name:E0C53, cost: 1\n",
            "Item 67 -> name:WpQ7hdE, cost: 1\n",
            "Item 68 -> name:C2y4Ot, cost: 1\n",
            "Item 69 -> name:Zon, cost: 0\n",
            "Item 70 -> name:ixkeYz, cost: 0\n",
            "Item 71 -> name:papa4kzl, cost: 1\n",
            "Item 72 -> name:DqOr, cost: 1\n",
            "Item 73 -> name:SVDIP1JZ, cost: 1\n",
            "Item 74 -> name:EIgvZbPl, cost: 1\n",
            "Item 75 -> name:SPGSmDl, cost: 0\n",
            "Item 76 -> name:UYYRU70, cost: 1\n",
            "Item 77 -> name:2nV, cost: 1\n",
            "Item 78 -> name:rXFlML, cost: 1\n",
            "Item 79 -> name:PsvrO2, cost: 1\n",
            "Item 80 -> name:9zOE22l7, cost: 1\n",
            "Item 81 -> name:SMKkzgd, cost: 1\n",
            "Item 82 -> name:6GAinpDW, cost: 1\n",
            "Item 83 -> name:1lc7PnJP, cost: 1\n",
            "Item 84 -> name:bsLTGty, cost: 0\n",
            "Item 85 -> name:nAJt0M, cost: 1\n",
            "Item 86 -> name:gX67pyJ5g, cost: 1\n",
            "Item 87 -> name:qrb, cost: 1\n",
            "Item 88 -> name:jJgKC14T, cost: 1\n",
            "Item 89 -> name:ziKj, cost: 1\n",
            "Item 90 -> name:QahvYcSNF, cost: 1\n",
            "Item 91 -> name:Ckdp, cost: 1\n",
            "Item 92 -> name:uR3zY, cost: 1\n",
            "Item 93 -> name:rjF, cost: 1\n",
            "Item 94 -> name:L8FV7RAfN, cost: 1\n",
            "Item 95 -> name:Lb78uex, cost: 1\n",
            "Item 96 -> name:ZqddEBFvv, cost: 1\n",
            "Item 97 -> name:T0EP, cost: 1\n",
            "Item 98 -> name:7i5, cost: 1\n",
            "Item 99 -> name:t2lGQcDCl, cost: 1\n",
            "***************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:06<00:00,  1.74s/it]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "******** Grid Search results : *******\n",
            "best_reward: -0.7777777777777777\n",
            "best parameters \n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.4, 'learning_rate': 0.1, 'gamma': 0.3}\n",
            "**************************************\n",
            " \n",
            " \n",
            " Execution time of grid Search: 6.967385768890381\n",
            "------------------> Average of series begins:  <------------------\n",
            "3 independent training/testing processes\n",
            "environnement name: envi_01\n",
            "Memory size: 1\n",
            "Number of items to recommend: 1\n",
            "--- We will test the following hyperparameters ---\n",
            "choice method: QlearningActionsTuples\n",
            "epochs: 10\n",
            "Reward hyper parameters: [1, 1]\n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.4, 'learning_rate': 0.1, 'gamma': 0.3}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 11.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " Execution time: 0.2815537452697754\n",
            "Qtable of the last series ------------------------------>\n",
            "[[   -inf  0.      0.     ...  0.      0.      0.    ]\n",
            " [ 0.        -inf  0.     ...  0.      0.      0.    ]\n",
            " [ 0.      0.        -inf ...  0.      0.      0.    ]\n",
            " ...\n",
            " [ 0.      0.      0.     ...    -inf  0.      0.    ]\n",
            " [ 0.      0.      0.     ...  0.        -inf  0.    ]\n",
            " [-0.0943  0.      0.     ...  0.      0.        -inf]]\n",
            "---------------------------------------------------->\n",
            " \n",
            "After the learning process : how often  is an item recommended? (total of all series) \n",
            "[  1.   0.   1.   3.   0.   1.  53.   3.   1.   0.   0.   0.   0.   0.\n",
            "   2.   0.   0.   0.   0.   1.   2.   0.   1.   0.   0.   0.   0.   1.\n",
            "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   2.   0.   1.   2.\n",
            "   1.   0.   3.   3.   0.   0.   0.   0.   3.   0.   1.   0.   0.   0.\n",
            "   1.   0.   0.   0.   0.   2.   1.   1.   0.   0.   3.   4.   2. 139.\n",
            " 138.   0.   0.   2.   0.   3.   0.   0.   0.   1.   0.   0.   1.   0.\n",
            "   1.   2.   2.   4.   0.   0.   0.   0.   1.   2.   0.   0.   0.   1.\n",
            "   1.   1.]\n",
            "After the learning process : how often  is an Action tuple recommended? (total of all series) \n",
            "Action list:\n",
            "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\n",
            "Action ids list:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Number of time selected (per action id):\n",
            "[  1.   0.   1.   3.   0.   1.  53.   3.   1.   0.   0.   0.   0.   0.\n",
            "   2.   0.   0.   0.   0.   1.   2.   0.   1.   0.   0.   0.   0.   1.\n",
            "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   2.   0.   1.   2.\n",
            "   1.   0.   3.   3.   0.   0.   0.   0.   3.   0.   1.   0.   0.   0.\n",
            "   1.   0.   0.   0.   0.   2.   1.   1.   0.   0.   3.   4.   2. 139.\n",
            " 138.   0.   0.   2.   0.   3.   0.   0.   0.   1.   0.   0.   1.   0.\n",
            "   1.   2.   2.   4.   0.   0.   0.   0.   1.   2.   0.   0.   0.   1.\n",
            "   1.   1.]\n",
            "Most recommended action: [69]\n",
            "------------------> Series ends <------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_sxaEXUbblC",
        "colab_type": "text"
      },
      "source": [
        "#### Q-Learning (Linear) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Dokr-fbekx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b868a899-3696-470f-d6aa-af18d32ada7e"
      },
      "source": [
        "print(\">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER MAKES SIMILAR CHOICES <<<<<<<<<<<<<<<<<<\")\n",
        "print(\"In this setting, the number of recommended items is 2. And only 2 items have a cost of 0. But the customer makes similar choices. Will the agent adapt?\")\n",
        "\n",
        "# ------------ Defining several parameters - others will be chosen by grid search --------------\n",
        "N_items = 100\n",
        "N_recommended = 1\n",
        "memory = 1\n",
        "choiceMethod =   'LinearQlearning'\n",
        "rewardType = 'Trust'\n",
        "behaviour = 'similar'\n",
        "rewardParameters = [1,1]\n",
        "steps = 10\n",
        "epochs = 3\n",
        "train_list = [True for u in range(3) ]+[ False, False ]\n",
        "p = 0.7\n",
        "\n",
        "#------------- Defining the environnement  -----------\n",
        "environnement = Environnement(N_items, N_recommended, behaviour,  rewardType , rewardParameters, proba_p=p )\n",
        "environnement.items.display(True)\n",
        "\n",
        "#------------- Defining the environnement  -----------\n",
        "# >>> Grid search over the parameters to get the best parameters\n",
        "gridSearch = GridSearch()\n",
        "num_avg = 3\n",
        "_ , params = gridSearch(num_avg, environnement, memory, choiceMethod, epochs, train_list, steps=steps)\n",
        "#params = {'gamma': 0.1, 'hidden_size': 10, 'epsilon': 0.2, 'learning_rate': 0.01, 'QLchoiceMethod': 'eGreedy'}\n",
        "\n",
        "\n",
        "#------------ launching the episode series : Average the learning processes results   ---------------\n",
        "#(less randomness in the plots), for statistical study, than the Series class\n",
        "num_avg = 3\n",
        "epochs = 10\n",
        "avgSeries = AverageSeries(num_avg, environnement, memory, choiceMethod, params, epochs, train_list, steps)\n",
        "Rewards = avgSeries.avgRewards\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot([str(i)+\"_\"+str(train_list[i]) for i in range(len(train_list))],Rewards, 'r-')\n",
        "plt.ylabel(\"Average reward per serie\")\n",
        "plt.xlabel(\"Serie id and type: true for training, false for testing  \")\n",
        "plt.title(\"Average results of \"+str(num_avg)+\" parallel training/testing sessions\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 13327.10it/s]\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER MAKES SIMILAR CHOICES <<<<<<<<<<<<<<<<<<\n",
            "In this setting, the number of recommended items is 2. And only 2 items have a cost of 0. But the customer makes similar choices. Will the agent adapt?\n",
            "---------------- Items ----------------\n",
            "Number of items: 100\n",
            "*** Items list: ***\n",
            "Item 0 -> name:pAZb, cost: 1\n",
            "Item 1 -> name:i1meR, cost: 1\n",
            "Item 2 -> name:HQ1LMOA, cost: 1\n",
            "Item 3 -> name:2WmU9yrB, cost: 0\n",
            "Item 4 -> name:VdWisK, cost: 1\n",
            "Item 5 -> name:LtZ, cost: 1\n",
            "Item 6 -> name:KpxMaNgzS, cost: 1\n",
            "Item 7 -> name:GAmhPb, cost: 1\n",
            "Item 8 -> name:bfbuaq3xg, cost: 1\n",
            "Item 9 -> name:CqxFVuu, cost: 1\n",
            "Item 10 -> name:8dHb1LfJs, cost: 1\n",
            "Item 11 -> name:NDqSiJ5, cost: 1\n",
            "Item 12 -> name:plmIab3, cost: 1\n",
            "Item 13 -> name:zmk, cost: 1\n",
            "Item 14 -> name:DpE, cost: 1\n",
            "Item 15 -> name:nl0r, cost: 1\n",
            "Item 16 -> name:GtSiYu, cost: 1\n",
            "Item 17 -> name:Eni, cost: 1\n",
            "Item 18 -> name:r7YnTfE, cost: 1\n",
            "Item 19 -> name:tyndxd, cost: 0\n",
            "Item 20 -> name:aGal, cost: 1\n",
            "Item 21 -> name:U98KUnd, cost: 1\n",
            "Item 22 -> name:SrT3, cost: 1\n",
            "Item 23 -> name:Ib1, cost: 1\n",
            "Item 24 -> name:fy92t6, cost: 1\n",
            "Item 25 -> name:DItEN, cost: 1\n",
            "Item 26 -> name:zc1cboE, cost: 1\n",
            "Item 27 -> name:NfY8J, cost: 1\n",
            "Item 28 -> name:yUGKJrJx3, cost: 1\n",
            "Item 29 -> name:qL1uw, cost: 1\n",
            "Item 30 -> name:wYI, cost: 1\n",
            "Item 31 -> name:8kJ, cost: 1\n",
            "Item 32 -> name:4uQ, cost: 1\n",
            "Item 33 -> name:NAb, cost: 1\n",
            "Item 34 -> name:MaIQY25T, cost: 1\n",
            "Item 35 -> name:KdjRR1O, cost: 1\n",
            "Item 36 -> name:H2so, cost: 1\n",
            "Item 37 -> name:wNnI, cost: 1\n",
            "Item 38 -> name:Fj7E9, cost: 1\n",
            "Item 39 -> name:gmE44x, cost: 1\n",
            "Item 40 -> name:fpkBWx, cost: 1\n",
            "Item 41 -> name:5gCSA, cost: 1\n",
            "Item 42 -> name:M3FL, cost: 1\n",
            "Item 43 -> name:QPZM, cost: 1\n",
            "Item 44 -> name:rbxvpq, cost: 1\n",
            "Item 45 -> name:G1kfJ, cost: 1\n",
            "Item 46 -> name:TZoK, cost: 1\n",
            "Item 47 -> name:J10FOJQ5Z, cost: 1\n",
            "Item 48 -> name:u4rwwzI, cost: 1\n",
            "Item 49 -> name:ytQo, cost: 1\n",
            "Item 50 -> name:cwnnuHVJ7, cost: 1\n",
            "Item 51 -> name:cvz4aBX0u, cost: 1\n",
            "Item 52 -> name:rQJL0g, cost: 1\n",
            "Item 53 -> name:ctLVMR, cost: 1\n",
            "Item 54 -> name:2CslZli, cost: 1\n",
            "Item 55 -> name:GpdvZ5j, cost: 1\n",
            "Item 56 -> name:JOVuwQy, cost: 1\n",
            "Item 57 -> name:27n01ZZ, cost: 1\n",
            "Item 58 -> name:9cg04CN, cost: 1\n",
            "Item 59 -> name:ZRd4uEz, cost: 1\n",
            "Item 60 -> name:7iF, cost: 1\n",
            "Item 61 -> name:aerLDWqX, cost: 0\n",
            "Item 62 -> name:KDD9x2qcq, cost: 1\n",
            "Item 63 -> name:wKkTIyDq, cost: 1\n",
            "Item 64 -> name:kAqfsjku, cost: 1\n",
            "Item 65 -> name:3ez0cY4U, cost: 1\n",
            "Item 66 -> name:XAoC, cost: 1\n",
            "Item 67 -> name:ejL4RYr, cost: 1\n",
            "Item 68 -> name:T1InflI, cost: 1\n",
            "Item 69 -> name:CsGagltRo, cost: 1\n",
            "Item 70 -> name:WL9f7qP, cost: 1\n",
            "Item 71 -> name:NrP, cost: 1\n",
            "Item 72 -> name:F7BJn, cost: 1\n",
            "Item 73 -> name:twv5nJE, cost: 1\n",
            "Item 74 -> name:3vCX4BvQN, cost: 1\n",
            "Item 75 -> name:YZMF, cost: 1\n",
            "Item 76 -> name:bSm0, cost: 1\n",
            "Item 77 -> name:MQy, cost: 1\n",
            "Item 78 -> name:7qTsBZgH, cost: 1\n",
            "Item 79 -> name:6swQaf, cost: 1\n",
            "Item 80 -> name:27cXlFtD3, cost: 1\n",
            "Item 81 -> name:YwRQiDIE, cost: 1\n",
            "Item 82 -> name:jb8, cost: 1\n",
            "Item 83 -> name:akq, cost: 1\n",
            "Item 84 -> name:Xx18, cost: 1\n",
            "Item 85 -> name:pqV, cost: 1\n",
            "Item 86 -> name:QdTs, cost: 1\n",
            "Item 87 -> name:xxxfz, cost: 1\n",
            "Item 88 -> name:vulF8UbxV, cost: 1\n",
            "Item 89 -> name:mZr, cost: 1\n",
            "Item 90 -> name:vDaOhcb5, cost: 1\n",
            "Item 91 -> name:CdshoEq, cost: 1\n",
            "Item 92 -> name:8JR, cost: 1\n",
            "Item 93 -> name:WIzf000, cost: 1\n",
            "Item 94 -> name:Jqyd, cost: 1\n",
            "Item 95 -> name:zwZD, cost: 1\n",
            "Item 96 -> name:Qlrd, cost: 1\n",
            "Item 97 -> name:ke10, cost: 1\n",
            "Item 98 -> name:ty8y, cost: 1\n",
            "Item 99 -> name:oymxYJ09, cost: 1\n",
            "***************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:24<00:00,  6.13s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "******** Grid Search results : *******\n",
            "best_reward: 10.444444444444445\n",
            "best parameters \n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.4, 'learning_rate': 1, 'gamma': 0.7}\n",
            "**************************************\n",
            " \n",
            " \n",
            " Execution time of grid Search: 24.53862738609314\n",
            "------------------> Average of series begins:  <------------------\n",
            "3 independent training/testing processes\n",
            "environnement name: envi_01\n",
            "Memory size: 1\n",
            "Number of items to recommend: 1\n",
            "--- We will test the following hyperparameters ---\n",
            "choice method: LinearQlearning\n",
            "epochs: 10\n",
            "Reward hyper parameters: [1, 1]\n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.4, 'learning_rate': 1, 'gamma': 0.7}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " Execution time: 1.0565755367279053\n",
            "Final weights: \n",
            "[[0.6074263 ]\n",
            " [0.62303168]\n",
            " [2.30037392]]\n",
            "Action list:\n",
            "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\n",
            "Action ids list:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Number of time selected (per action id):\n",
            "[ 0.  0.  5. 34.  0.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  6.  0.\n",
            "  0. 34.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  0.  0.\n",
            "  0.  0.  0.  0. 15.  0.  0.  0. 10.  0.  0.  0.  0.  0.  5.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0. 15.  0.  0.  9.  0.  0.  0.  0.  9.  0.  0.\n",
            "  0.  5. 10.  0.  0.  1.  0.  0.  1.  0.  5.  0.  5.  0.  0.  0.  5.  5.\n",
            "  5.  5.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
            "Most recommended action: [3]\n",
            "------------------> Series ends <------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g89WDgJhyCP1",
        "colab_type": "text"
      },
      "source": [
        "#### Q-Learning (Deep) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkZlsWDkyD_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ded9ab62-6c85-4589-da17-46fbd167c4ae"
      },
      "source": [
        "print(\">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER ALWAYS CHOOSES THE FIRST RECOMMENDATION <<<<<<<<<<<<<<<<<<\")\n",
        "\n",
        "# ------------ Defining several parameters - others will be chosen by grid search --------------\n",
        "N_items = 100\n",
        "N_recommended = 1\n",
        "memory = 1\n",
        "choiceMethod =  'DeepQlearning'\n",
        "rewardType = 'Trust'\n",
        "behaviour = 'similar'\n",
        "rewardParameters = [1,1]\n",
        "steps = 10\n",
        "epochs = 3\n",
        "train_list = [True for u in range(3) ]+[ False, False ]\n",
        "\n",
        "#------------- Defining the environnement  -----------\n",
        "environnement = Environnement(N_items, N_recommended, behaviour,  rewardType , rewardParameters )\n",
        "\n",
        "\n",
        "environnement.items.display(True)\n",
        "\n",
        "\n",
        "#Create model\n",
        "#model = nn.Sequential(\n",
        "#    nn.Linear(memory+2*N_recommended, 20),\n",
        "#    nn.SELU(),\n",
        "#    nn.Linear(20, 5),\n",
        "#    nn.SELU(),\n",
        "#    nn.Linear(5, 1),\n",
        "#    nn.Sigmoid()\n",
        "\n",
        "#)\n",
        "#trainable_layers = [0,2,4]\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(memory+2*N_recommended, 10),\n",
        "    nn.SELU(),\n",
        "    nn.Linear(10, 1)\n",
        ")\n",
        "\n",
        "trainable_layers = [0,2]\n",
        "\n",
        "deepQModel = {'model': model, 'trainable_layers': trainable_layers}\n",
        "\n",
        "# >>> Grid search over the parameters to get the best parameters\n",
        "gridSearch = GridSearch()\n",
        "num_avg = 3\n",
        "_ , params = gridSearch(num_avg, environnement, memory, choiceMethod, epochs, train_list, steps=steps, more_params = None, deepQModel=deepQModel)\n",
        "\n",
        "print(\"Testing the Grid Search parameters: \")\n",
        "\n",
        "#------------ launching the episode series : Average the learning processes results   ---------------\n",
        "#(less randomness in the plots), for statistical study, than the Series class\n",
        "num_avg = 3\n",
        "epochs = 10\n",
        "avgSeries = AverageSeries(num_avg, environnement, memory, choiceMethod, params, epochs, train_list, steps, deepQModel)\n",
        "Rewards = avgSeries.avgRewards\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot([str(i)+\"_\"+str(train_list[i]) for i in range(len(train_list))],Rewards, 'r-')\n",
        "plt.ylabel(\"Average reward per serie\")\n",
        "plt.xlabel(\"Serie id and type: true for training, false for testing  \")\n",
        "plt.title(\"Average results of \"+str(num_avg)+\" parallel training/testing sessions\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 13301.74it/s]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>>>>> TESTING THE AGENT : IN CASE THE CUSTOMER ALWAYS CHOOSES THE FIRST RECOMMENDATION <<<<<<<<<<<<<<<<<<\n",
            "---------------- Items ----------------\n",
            "Number of items: 100\n",
            "*** Items list: ***\n",
            "Item 0 -> name:u7jV2f0F, cost: 1\n",
            "Item 1 -> name:w6Ul, cost: 1\n",
            "Item 2 -> name:iXTP6Ul, cost: 1\n",
            "Item 3 -> name:lK07OR, cost: 1\n",
            "Item 4 -> name:xFRbY, cost: 1\n",
            "Item 5 -> name:wFF, cost: 1\n",
            "Item 6 -> name:T3PdbD6, cost: 1\n",
            "Item 7 -> name:V9emyA4, cost: 1\n",
            "Item 8 -> name:pkSABka, cost: 1\n",
            "Item 9 -> name:Ypbb2awz, cost: 1\n",
            "Item 10 -> name:SHok, cost: 1\n",
            "Item 11 -> name:BVa, cost: 1\n",
            "Item 12 -> name:61h, cost: 1\n",
            "Item 13 -> name:gwIBdk, cost: 0\n",
            "Item 14 -> name:nyFlodfjU, cost: 1\n",
            "Item 15 -> name:3cWCV, cost: 1\n",
            "Item 16 -> name:qROXiY, cost: 1\n",
            "Item 17 -> name:ZdNX, cost: 1\n",
            "Item 18 -> name:3KSJTB, cost: 1\n",
            "Item 19 -> name:wP9XaV9vx, cost: 0\n",
            "Item 20 -> name:Buyn2us, cost: 1\n",
            "Item 21 -> name:9NBISSe, cost: 1\n",
            "Item 22 -> name:Kjs9P8BuW, cost: 1\n",
            "Item 23 -> name:KTE7Q, cost: 1\n",
            "Item 24 -> name:GqWfNK1, cost: 1\n",
            "Item 25 -> name:626BqDzN, cost: 1\n",
            "Item 26 -> name:Rs7z, cost: 1\n",
            "Item 27 -> name:9FtnMDv, cost: 1\n",
            "Item 28 -> name:tvzIoM, cost: 1\n",
            "Item 29 -> name:XBimqeB6, cost: 1\n",
            "Item 30 -> name:u9wSv, cost: 1\n",
            "Item 31 -> name:pd6RKj0, cost: 1\n",
            "Item 32 -> name:G0YQH3vKv, cost: 1\n",
            "Item 33 -> name:zHOl, cost: 1\n",
            "Item 34 -> name:EgFOYlAm, cost: 1\n",
            "Item 35 -> name:FX132, cost: 1\n",
            "Item 36 -> name:eL1WVu5, cost: 1\n",
            "Item 37 -> name:yGE9EYj, cost: 0\n",
            "Item 38 -> name:l8zolcv, cost: 1\n",
            "Item 39 -> name:wXxbeW, cost: 1\n",
            "Item 40 -> name:Sru, cost: 0\n",
            "Item 41 -> name:eyO, cost: 1\n",
            "Item 42 -> name:hsGCOeZFt, cost: 1\n",
            "Item 43 -> name:2JQexL, cost: 1\n",
            "Item 44 -> name:xCt, cost: 1\n",
            "Item 45 -> name:02kHo, cost: 1\n",
            "Item 46 -> name:IQQtc4, cost: 1\n",
            "Item 47 -> name:cTLRz, cost: 1\n",
            "Item 48 -> name:pypkd, cost: 1\n",
            "Item 49 -> name:eMC03, cost: 1\n",
            "Item 50 -> name:nUq5Eblno, cost: 1\n",
            "Item 51 -> name:9AwmGO, cost: 1\n",
            "Item 52 -> name:BwDxD, cost: 1\n",
            "Item 53 -> name:HhNIB, cost: 1\n",
            "Item 54 -> name:td8iI, cost: 1\n",
            "Item 55 -> name:gzKe7C, cost: 1\n",
            "Item 56 -> name:xsZP, cost: 1\n",
            "Item 57 -> name:KGe, cost: 1\n",
            "Item 58 -> name:DkRuZnxh, cost: 1\n",
            "Item 59 -> name:5zs, cost: 1\n",
            "Item 60 -> name:XRU9, cost: 1\n",
            "Item 61 -> name:wA3NG, cost: 1\n",
            "Item 62 -> name:BUadrc, cost: 1\n",
            "Item 63 -> name:g2BUYUURS, cost: 0\n",
            "Item 64 -> name:qoL, cost: 1\n",
            "Item 65 -> name:5l49NSmi, cost: 1\n",
            "Item 66 -> name:qHJ9Iq, cost: 1\n",
            "Item 67 -> name:uvDWT, cost: 1\n",
            "Item 68 -> name:ZnVOjUJa2, cost: 1\n",
            "Item 69 -> name:EhHn3n, cost: 1\n",
            "Item 70 -> name:810, cost: 1\n",
            "Item 71 -> name:u640I, cost: 1\n",
            "Item 72 -> name:s2NOMDm, cost: 1\n",
            "Item 73 -> name:YTUIdpoh, cost: 1\n",
            "Item 74 -> name:PkOi, cost: 1\n",
            "Item 75 -> name:HiIKD7, cost: 1\n",
            "Item 76 -> name:ATIrsimNM, cost: 1\n",
            "Item 77 -> name:ZJ0, cost: 1\n",
            "Item 78 -> name:C5qXI, cost: 1\n",
            "Item 79 -> name:DZdypDMG, cost: 1\n",
            "Item 80 -> name:aIt, cost: 1\n",
            "Item 81 -> name:ldeeizVhK, cost: 1\n",
            "Item 82 -> name:Qa4Dg, cost: 1\n",
            "Item 83 -> name:tJjmlV, cost: 1\n",
            "Item 84 -> name:SprWZXza, cost: 1\n",
            "Item 85 -> name:xLG, cost: 1\n",
            "Item 86 -> name:CZP0, cost: 1\n",
            "Item 87 -> name:iKPdSc, cost: 1\n",
            "Item 88 -> name:neKe, cost: 1\n",
            "Item 89 -> name:rRJQGt, cost: 1\n",
            "Item 90 -> name:NLSTVKO, cost: 1\n",
            "Item 91 -> name:kMPV, cost: 1\n",
            "Item 92 -> name:jfNz6Fl, cost: 1\n",
            "Item 93 -> name:Q6TAXTwD, cost: 1\n",
            "Item 94 -> name:GlZPUw5m, cost: 1\n",
            "Item 95 -> name:cN5emJG, cost: 1\n",
            "Item 96 -> name:u1Xy, cost: 1\n",
            "Item 97 -> name:Q2MnYHC, cost: 1\n",
            "Item 98 -> name:Sw24ZDxdy, cost: 1\n",
            "Item 99 -> name:Dto8Z, cost: 1\n",
            "***************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [02:38<00:00, 52.71s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "******** Grid Search results : *******\n",
            "best_reward: 5.444444444444444\n",
            "best parameters \n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.3, 'learning_rate': 0.1, 'gamma': 0.5}\n",
            "**************************************\n",
            " \n",
            " \n",
            " Execution time of grid Search: 158.1408088207245\n",
            "Testing the Grid Search parameters: \n",
            "------------------> Average of series begins:  <------------------\n",
            "3 independent training/testing processes\n",
            "environnement name: envi_01\n",
            "Memory size: 1\n",
            "Number of items to recommend: 1\n",
            "--- We will test the following hyperparameters ---\n",
            "choice method: DeepQlearning\n",
            "epochs: 10\n",
            "Reward hyper parameters: [1, 1]\n",
            "{'QLchoiceMethod': 'eGreedy', 'epsilon': 0.3, 'learning_rate': 0.1, 'gamma': 0.5}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:14<00:00,  7.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " Execution time: 21.886444091796875\n",
            "--------------------------> Q learning ( neural network approximation) method :\n",
            " memory: 1\n",
            " number of items to recommend at each step : 1\n",
            " learning rate: 0.1\n",
            " gamma: 0.5\n",
            "trainable layers ids: [0, 2]\n",
            "Model:\n",
            "Sequential(\n",
            "  (0): Linear(in_features=3, out_features=10, bias=True)\n",
            "  (1): SELU()\n",
            "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            " <---- Weight and bias of Layer 0 ---->\n",
            "Weight -->\n",
            "tensor([[ 0.2380, -0.6687, -0.1908],\n",
            "        [ 0.3465, -0.5230,  0.6571],\n",
            "        [-0.0415,  0.0031, -0.1102],\n",
            "        [-0.3351,  0.1396,  0.4381],\n",
            "        [ 0.0008, -0.4386,  0.2035],\n",
            "        [-0.0844, -0.0456,  0.4475],\n",
            "        [ 0.2865,  0.3203, -0.7128],\n",
            "        [ 0.0068, -0.6268,  0.6780],\n",
            "        [ 0.5724,  0.1314,  0.5357],\n",
            "        [-0.3739, -0.0153,  0.6251]])\n",
            "Bias -->\n",
            "tensor([ 0.2684, -0.1638,  0.5294,  0.0923,  0.5634,  0.5065, -0.5029, -0.3738,\n",
            "         0.4189,  0.1353])\n",
            "\n",
            " <---- Weight and bias of Layer 2 ---->\n",
            "Weight -->\n",
            "tensor([[ 0.2547,  0.4196,  0.2269,  0.2202,  0.1691,  0.3269, -0.4282,  0.3927,\n",
            "          0.1489,  0.5042]])\n",
            "Bias -->\n",
            "tensor([0.0153])\n",
            "----------------------------------------------------\n",
            "Action list:\n",
            "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\n",
            "Action ids list:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Number of time selected (per action id):\n",
            "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 48.  0.  0.  0.  0.\n",
            "  0. 49.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0. 47.  0.  0. 50.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  6.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            "Most recommended action: [40]\n",
            "------------------> Series ends <------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}